# Неделя 6: Деревья Решений и Сложность Алгоритмов

*Редактору: нужно сократить лонгрид, спасите…*

*Время чтения: 80 минут* 

**Контекст:** 

В курсе машинного обучения мы уже заложили фундамент из линейных моделей — ровных, но жёстких кирпичей, задающих простую форму нашего будущего “Дома Знаний”. Решающие деревья кладутся следующим слоем: это «фигурные» кирпичи, которые позволяют стенам изгибаться под сложные контуры реальных данных, автоматически находя пороги и взаимодействия признаков. Освоив их, ты поймешь, как строить модели, сохраняющие интерпретируемость, но выходящие за пределы линейных границ — то есть укрепит ту часть Дома, где нужна гибкость без потери прочности.

**Применение:**

Освоив решающие деревья, ты научишься строить модели, которые объясняют свои выводы прозрачными «если‑то» правилами — это особенно ценно, когда нужно убедить бизнес‑заказчика или регулятора. Алгоритм помогает там, где важны пороговые эффекты и смешанные типы данных: в оценке кредитного риска, медицинской диагностике, маркетинговой сегментации, обнаружении брака на производстве. Например, банк может мгновенно отклонять подозрительные операции по цепочке вопросов «сумма > 500 $? клиент за границей?», а врач — классифицировать опухоль как доброкачественную или злокачественную по набору клинических показателей. Разобравшись с деревьями, ты получишь базу для перехода к более мощным — ансамблевым — методам (Случайным Лесам, Градиентному Бустингу), сильно повышающим точность за счет определенной потери интерпретируемости.

**План:**

1. Введение в деревья решений
2. Теоретические основы решающих деревьев
   1. Технические аспекты
   2. Обучение деревьев
   3. Тонкости в обучении
3. Применение метода решающих деревьев
   1. Преимущества и недостатки деревьев
   2. Деревья VS Линейные модели
4. Обобщающая способность, переобучение и сложность ML моделей
   1. Статистические основы
   2. Оценка параметров в статистике
   3. Bias-Variance-Noise разложение и Переобучение
5. Обобщающая способность решающих деревьев
   1. Pre-pruning методы
   2. Post-pruning методы

---

## **1. Введение в деревья решений**

Линейные методы для регрессии и классификации, рассмотренные нами ранее, высоко ценятся в научном сообществе специалистов по анализу данных, а также имеют широкое практическое применение в самых разных отраслях. Действительно, линейные модели, включающие линейную и логистическую регрессии, выгодно выделяются на фоне других ML алгоритмов своей простотой и высокой интерпретируемостью результатов. Помимо всего прочего, линейные алгоритмы привлекательны быстрой обучаемостью, способностью работать с большим количеством объектов и признаков, легкой регуляризуемостью и, в целом, своей **параметрической** природой, что означает фиксированное (независимое от размера входных данных) и, обычно, небольшое количество параметров, которые необходимо “зафиттить” в процессе обучения модели. Например, простая линейная регрессия вида

$$
\hat{f}(x) = \hat{\beta_0} + \hat{\beta_1} x
$$

имеет всего два параметра для обучения — $\hat{\beta_0}$ и $\hat{\beta_1}$, и этими двумя параметрами можно описать всю обученную модель вне зависимости от того, какое количество входных данных изначально имеется. Именно это свойство и гарантирует быстрое обучение на данных и высокую интерпретируемость полученных результатов.

Однако это свойство параметричности, в совокупностью с линейностью моделей, в то же время **серьезно ограничивает** **гибкость** модели, так как подразумевает линейную зависимость между целевой переменной и признаками, что редко встречается в реальном мире. Даже в случае наличия полиномиальных признаков, как, например, в

$$
\hat{g}(x) = \hat{\beta_0} + \hat{\beta_1} x + \hat{\beta_2} x^2 + \hat{\beta_3} x^3,
$$

модель все равно строго ограничена степенной сложностью этих признаков (например, в этом случае, модель максимально сможет обучиться кубической зависимостью, но не полиномиальной зависимостью более высшего порядка или зависимостью других типов). Более того, такой подход требует выбора типа нелинейности и может приводить к **комбинаторному взрыву,** когда количество независимых переменных к рассмотрению становится чрезмерно большим, что сильно вредит стабильности модели.

На этой неделе мы рассмотрим новый класс моделей – **Деревья решений (Decision Trees)**. Ключевой особенностью этих моделей является крайне высокая интерпретируемость результатов при условии сверхгибкости, позволяющей восстанавливать нелинейные зависимости произвольной сложности. Эта пластичность является следствием **непараметричности** подхода – в рамках решающих деревьев, мы не фиксируем заранее количество параметров для обучения, что позволяет нам точнее адаптировать модель под существующие данные, улавливая более “извилистые” зависимости. На статистическом языке, мы говорим, что количество **степеней свободы** в моделях решающих деревьев варьируется (в отличие от ЛинРега, где оно заранее зафиксировано), и может достигать огромных значений, что говорит об очень высокой пластичности деревьев. Давай разберем, что такое дерево решений и как оно используется в реальной жизни.

**__Определение.__** **Дерево решений** — это модель машинного обучения, представляющая собой древовидную структуру, в которой каждый узел (или вершина) представляет собой условие на каком-либо признаке (фиче), а каждый лист — это конечный прогноз (или решение) для данного набора признаков. Давай разберем наглядный пример.


[https://docs.google.com/drawings/d/1ONNEzWuGrX3TdqonbkdJ8Camb0eGtMkE723zucQdBw0/edit?usp=sharing](embed:https://docs.google.com/drawings/d/1ONNEzWuGrX3TdqonbkdJ8Camb0eGtMkE723zucQdBw0/edit?usp=sharing "1")

         *Рисунок 1: Бинарное Решающее дерево. Признаки: Индекс Массы Тела (количественный),                                Диабет (качественный), Фастфуд (количественный). Целевая переменная –                                                                            Образ Жизни (качественная).*

Представим, что мы работаем врачом, и к нам приходит пациент с болями в желудке. Нам нужно провести осмотр и выдвинуть первую гипотезу о причине болей. Очевидно, что болеть в желудке может из-за неправильного питания, потому мы можем опросить пациента на “здоровость” его образа жизни. Однако этот опрос будет давать ненадежные результаты, так как пациент всегда может соврать или приукрасить :) Более надежным методом будет наблюдение за данными пациента, которое позволит нам сделать первые выводы о причине его болей. 

По показателям прошлых пациентов и знании их образа жизни, мы можем построить бинарное решающее дерево (см. Рисунок 1). Рассмотрим компоненты деревьев решений:

1. **Внутренние вершины, или узлы (internal nodes)**, которые разбивают признаки на регионы согласно порогам. Включают в себя **корень (root)** – первую внутреннюю вершину дерева. На рисунке 1, внутренние вершины включают *{ИМТ > 23}* (корень), *{Диабет: есть}* и *{Фастфуд > 2}*, где 
   1. ИМТ – Индекс Массы Тела, принимает количественные значения (вещественные числа);
   2. Диабет – категориальный признак, принимающий значения из множества {Есть, Отсутствует};
   3. Фастфуд – количественный признак, принимающий значения из множества натуральных чисел, и означающий количество приемов “вредной” пищи в неделю.
2. **Терминальные вершины, или листья (terminal node/leaf)**, которые не делятся дальше и хранят итоговое предсказание – класс (или вероятность классов) в задачах классификации и число в задачах регрессии. На рисунке 1 представлены 4 листа, определяющих пациентов по классам целевой переменной Образ жизни, которая принимает значения из множества {ЗОЖник, Сладкоежка}. Так как целевая переменная принимает категориальные значения, мы имеем дело с задачей классификации, а дерево на рисунке 1 является деревом классификации.
3. **Дуги, или ребра** **(branch/edge)**, которые связывают родительскую и дочернюю вершины. Соответствуют одному исходу – Да или Нет.

Таким образом, по рисунку 1, мы знаем, что если ИМТ у пациента больше 23, и у него нет диабета, значит, можно сделать выводы (с определенной вероятностью) о неправильном питании пациента, и зачислить такого пациента в категорию Сладкоежек. Та же участь ждет пациентов хоть и с небольшим ИМТ (меньше 23), но потребляющим фастфуд чаще двух раз в неделю. Все остальные пациенты могут рассматриваться как ЗОЖники (с определенной вероятностью). Получается, что если наш пациент относится к разряду Сладкоежек, первой нашей гипотезой о причине болей в желудке уже станет *гастрит/язвенная болезнь*. 

Очевидно, что в реальной жизни факторов, от которых зависит образ питания намного больше – количество потребляемых углеводов/белков/жиров в день, количество приемов пищи, время приемов пищи и тд. Однако уже такое небольшое дерево решений может помочь нам с постановкой диагноза. Обрати внимание на главное достоинство модели – исключительную интерпретируемость и простоту в понимании результатов (по крайней мере, в деревьях с небольшой глубиной). Есть также мнение, что дерево решений по сравнению с линейными моделями лучше отображает способ принятия решений людьми, которые часто неосознанно руководствуются алгоритмом [У человека есть “лишние килограммы”? Если да, то есть ли у него диабет? Если есть, вероятно, он ведет здоровый образ жизни, а если нет, то скорее всего он любит поесть сладкого или вредного]. 

Теперь двигаемся от частного к общему. В decision‑tree‑литературе принято говорить не об «одном типе» дерева, а о **семействе методов**, которые можно разложить по нескольким независимым осям. Ниже — самые базовые «классификационные шкалы». Комбинируя их, легко описать почти любой алгоритм от классических до более современных моделей:

1. По типу целевой переменной:
   1. Дерево классификации – предсказывает метку класса или вероятность классов;
   2. Дерево регрессии – предсказывает вещественную непрерывную величину.
2. По бинарности разбиения узлов:
   1. Бинарное разбиение – каждый узел делится на два под-узла (рис. 1);
   2. Мульти-сплит – узлы делятся на >2 под-узла.
3. По форме разделяющей поверхности (см. ниже):
   1. Параллельно осям координат (осевое разбиение);
   2. По линейной (и даже нелинейной) комбинации признаков.
4. По стратегии построения:
   1. Top-down, сверху-вниз – построение от корня к листьям;
   2. Bottom-up, снизу-вверх – построение от листьев к корню;
   3. Глобальная оптимизация.
5. По обработке данных:
   1. Batch training – дерево обучается сразу на всех данных;
   2. Online training – дерево постепенно дообучается на новых данных.

На самом деле, критериев для классификации деревьев больше, но тут указаны самые базовые. По мере прохождения дальше по лонгриду, будет становиться более понятным каждый отдельный критерий. На основании этих критериев и отличаются друг от друга разные **алгоритмы** деревьев решений: например, алгоритм **C4.5** поддерживает и вещественные, и категориальные признаки, тогда как алгоритм **ID3** работает только с категориальными переменными. В рамках этого лонгрида мы будем в основном описывать стандартный и распространенный алгоритм деревьев решений **CART – Classification and Regression Trees**. CART является золотой серединой: он достаточно мощный, чтобы работать «из коробки» на реальных задачах, и в то же время достаточно простой, чтобы его могли внедрить и понять инженеры. В то же время, CART предполагает бинарные разбиения узлов (и в этом лонгриде только на бинарном разбиении мы и сфокусируемся) и предъявляет минимальные требования к данным – CART не чувствителен к масштабу и к монотонным преобразованиям, а также допускает пропуски в данных, что сильно упрощает препроцессинг этих данных в реальных задачах.

А теперь давай поговорим о графическом представлении деревьев. На рисунке 1 представлен один из способов представить дерево решений с помощью буквально иллюстративной древовидной структуры, где дерево растет сверху вниз. На самом деле, одно и то же дерево можно представить разными способами:

 ![](/api/attachments.redirect?id=d8a82efc-49f4-4f99-8527-b5267ab25031 "aspect=1")

*Рисунок 2: Разные способы представления дерева регрессии. Первый способ: верхний левый/        правый рисунок; второй способ: нижний левый рисунок; третий способ: нижний правый                                              рисунок (источник: ESL, T. Hastie & R. Tibshirani, 2023).*

Таким образом, на рисунке 2 мы видим три способа иллюстративного представления дерева регрессии. Все рисунки, кроме левого верхнего, относятся к одному и тому же дереву, которое обрабатывает два непрерывных признака $X_1$ и $X_2$ и разбивает все пространство признаков на регионы, где в последствии каждому отдельному региону присваивается определенное значение непрерывного целевого признака Y. 

Теперь чуть подробнее о рисунке 2. Нижнее левое представление относится к тому самому древовидному представлению из рисунка 1 – мы последовательно разбиваем два признака по конкретным условиям, и в итоге приходим к пяти терминальным вершинам (или **регионам**), которые представляют собой вещественные числа (так как дерево регрессионное) из множества значений целевой переменной Y. Эти пять регионов (и присваиваемые им значения Y) и являются предсказаниями дерева. То же самое дерево можно представить в виде разбиения пространства признаков на регионы (правый верхний рисунок). И снова, каждому из регионов присваивается определенная оценка Y. Эта оценка хорошо представлена на нижнем правом рисунке – фактически, это то же самое разбиение, но уже в виде двумерной функции $X → \hat{f}(X)$, где Х – вектор признаков $Х_1$ и $Х_2$, а $\hat{f}(X)$ – наша оценка зависимости между Х и Y. Грубо говоря, правый верхний и правый нижний рисунки показывают одно и то же, но правый нижний рисунок отображает значения наших предсказаний для каждого региона $R_1, R_2, R_3, R_4, R_5$. По сути, правый нижний рисунок показывает предсказания Y для каждого значения $X_1$ и $X_2$, и этот график можно сравнить с двумерным графиком предсказаний модели линейной регрессии, где плоскость предсказаний *линейная*, а не ступенчатая, как здесь. Таким образом, уже по этому графику можно сделать выводы о гораздо большей гибкости алгоритмов деревьев решений по сравнению с линейными моделями.

Три рассмотренных представления показывают структуру дерева, обученного по методу CART, то есть такого дерева, которое удовлетворяет условиям:

- Последовательное разбиение пространства признаков, то есть разбиваем один общий регион на два региона, далее разбиваем один из двух получившихся регионов на еще два региона, далее разбиваем один из трех регионов на еще два региона и тд. Этот способ разбиения называется **жадным (greedy)**, и во второй главе мы рассмотрим его детальнее;
- Бинарное разбиение узлов дерева, то есть каждый узел разбивается на два под-узла;
- Разбиение пространства признаков одномерно, то есть каждое условие разбиения внутренних вершин зависит только от одной переменной: ${X_1 <= t_1, X_2 <= t_2, …}$ В таком случае, разбиение называется **осевым**, то есть деление пространства на регионы происходит параллельно осям координат (см. верхний правый рисунок 2). Но если бы разбиение, например, происходило по типу $X_1 X_2 <= t_1$, то оно бы считалось многомерным, и регионы на правом верхнем рисунке имели бы непрямоугольную форму.

Эти три условия построения дерева являются последствием применения метода **Рекурсивного Бинарного Разбиения (Recursive Binary Splitting)**, свойственного алгоритму CART. Однако, как мы видим на рисунке 2, левое верхнее представление не соответствует дереву, обученному по этому методу. Таким образом, исследовать дальше мы будем только те деревья, обученные про принципу РБР.

Кстати, бинарная древовидная CART структура (построенная по методу РБР) *точно* описывается условной инструкцией if-else, которая встречается во многих языках программирования. Вот пример применения на языке Python (по примеру из рис. 1):

```python
def predict_diet(bmi, diabetes, junkfood_number):
    """
    Очень простое «дерево» в виде вложенных if‑else.
    Возвращает название образа жизни и диеты.
    """
    # Узел 1 (корень)
    if bmi > 23:
        # Узел 2
        if diabetes = yes:
            return "healthy style"        # Лист 1
        else:
            return "sweet tooth"          # Лист 2
    else:
        # Узел 3
        if junkfood_number > 2:
            return "sweet tooth"  # Лист 3
        else:
            return "healthy style"   # Лист 4
```

Далее обученную древовидную **функцию** predict_diet можно использовать в целях предсказания образа жизни среди новых пациентов.

Кстати говоря о математических функциях – в следующей главе мы повысим градус сложности и рассмотрим деревья решений с более технической точки зрения, проанализируем, как обучать деревья и чем отличаются деревья регрессий от деревьев классификаций, а также изучим тонкости не только CART, но и более продвинутых методов построения деревьев.

---

## **2. Теоретические основы решающих деревьев**

### **2.1. Технические аспекты дерева решений**

В этой секции мы пройдемся по пунктам:

- Математически определим, что такое дерево решений (2.1.1.);
- Рассмотрим дерево с точки зрения древовидной структуры и определим, что происходит в каждой внутренней (2.1.2.) и терминальной (2.1.3.) вершинах. Полезно будет обращаться к рисунку 1, к левому нижнему рисунку 2, а также к рисунку 3.
- Рассмотрим дерево с точки зрения разбиения пространства признаков на регионы (2.1.4.). Полезно будет обращаться к правому верхнему рисунку 2.
- Посмотрим на то, как работает обученное дерево и как с помощью дерева решений можно делать предсказания (2.1.5.). Полезно будет обращаться к правому нижнему рисунку 2.

Начнем с математического определения решающих деревьев.

 ![](/api/attachments.redirect?id=ebca8bae-7d8f-46ef-a0e6-838e36ff962c "aspect=1")

        *Рисунок 3: сравнение обычного графа с графом-деревом. В дереве указаны все                                  внутренние и терминальные вершины, рёбра помечены значениями 1 и 0.*

#### **2.1.1. Определение дерева решений**

Пусть

- $\mathcal X$**— пространство признаков** (если все признаки вещественные, тогда $\mathcal X\subseteq\mathbb R^{d}$)
- $\mathcal Y$ **— пространство ответов (для классификации** $\mathcal Y={1,\dots ,K}$**, для регрессии** $\mathcal Y=\mathbb R)$**.**

**Дерево решений** $T$ согласно **теории графов** задаётся как упорядоченное ориентированное дерево $T=(V,E,r)$ с корнем $r∈V$, где $E$ – множество ребер между вершинами, а множество вершин $V$ разбивается на

- Внутренние вершины $V_{\text{int}}$ (решающие узлы);
- Листья $V_{\text{leaf}}$​.

#### **2.1.2. Функции в узлах**

В дереве, каждой внутренней вершине $v\in V_{\text{int}}$ сопоставляется **булева функция (boolean function)**: 

$$
h_v:\mathcal X\to{0,1}
$$

Обычно в случае, если деление внутри вершины происходит по количественной переменной, тогда $h_v(x)=\mathbb I(x_{j_v}\le t_v)$, где $x$ – объект (наблюдение), а $\mathbb I(...)$ – индикаторная функция, которая возвращает 1, если соблюдается условие внутри фигурных скобок, и 0, если условие не соблюдается. Внутри этой функции $x_{j_v}$ – количественный признак, по которому происходит деление, $j_v\in{1,\dots ,d}$ — индекс признака, а $t_v\in\mathbb R$ — порог. Аналогично, в случае, если деление происходит по категориальной переменной, функцией обычно будет $h_v(x)=\mathbb I(x_{j_v}\subset C_v)$, где $x_{j_v}$ – категориальный признак, по которому происходит деление, $j_v\in{1,\dots ,d}$ — индекс признака, а $C_v$ — подмножество категорий признака $x_{j_v}$. 

Рёбра из $v$ помечены значениями 1 и 0 (рисунок 3). При обходе дерева объект $x$ идёт налево, если $h_v(x)=1$, и направо, если $h_v(x)=0$.


:::tip
По сути, мы сейчас математическим образом описали все то, что интуитивно разбирали в первой секции этой главы.

:::


:::info
Указанные выше функции $h_v(x)$ применимы только в тех случаях, когда деление происходит по одному признаку (в таком случае эти функции называются одномерными предикатами, а деление называется осевым). Подробнее это условие описывается выше, в третьем пункте по рекурсивному бинарному разбиению.

Однако необходимо помнить, что деление пространства признаков на регионы может происходить сразу по нескольким признакам, например, если деление внутренней вершины происходит по условию “если произведение первого и второго признаков больше нуля, тогда…”. Мы такие случаи рассматривать не будем, так как они приводят к **серьезному переобучению** **(severe overfitting)** модели, и требуют очень аккуратного подхода. Тему по переобучению алгоритмов мы затронем позже.

:::

 ![](/api/attachments.redirect?id=f9327ed9-90bf-479a-b504-d6abc578fe2d "aspect=1")

*Рисунок 4: Дерево классификации в разных представлениях. Два признака, два класса целевой переменной. В левом рисунке, листья принимают значения вероятностей первого класса, а под листьями указано, какой процент наблюдений находится в данном регионе (листе). Правый рисунок показывает разбиение пространства на регионы – чем темнее регион, тем выше вероятность первого класса. Центральный рисунок показывает двумерную функцию оценки вероятностей первого класса для каждого региона. Источник: Википедия,                                           <https://en.wikipedia.org/wiki/Decision_tree_learning>.*

#### **2.1.3. Метки в листьях**

Каждому листу $\ell\in V_{\text{leaf}}$​ назначается константное значение $c_\ell\in\mathcal Y$. В случае с деревом регрессии, $c_\ell$ будет принимать значения из какого-то бесконечного множества чисел (обычно вещественных чисел), а в случае с деревом классификации – значения из конечного множества меток (классов). Также в случае классификации, каждому листу могут присваиваться вероятности каждого из классов (или одного класса, см. рисунок 4), и в таком случае $c_\ell$ будет вектором вероятностей, с размерностью в количество классов, которые может принимать целевая переменная.


:::info
Стоит упомянуть, что один родительский узел может породить два дочерних узла с **одинаковым** предсказанием, особенно в задачах классификации (см. рисунок ниже). Такое может происходить для того, чтобы разделить регион на два региона с “более уверенной” и “менее уверенной” отметкой, где в первом регионе вероятность предсказанной отметки выше, чем во втором регионе.

:::

 ![](/api/attachments.redirect?id=3b1830b1-9762-452c-8b34-aca3825b0931 "aspect=0.6789115646258504")

*Рисунок *. Источник: ISL; Hastie, Tibshirani.*

#### **2.1.4. Разбиение пространства признаков**


:::tip
**Рекурсивный алгоритм** – метод, при котором алгоритм вызывает “сам себя”. Он берёт большую задачу, делит её на чуть меньшую копию той же задачи и поручает её «самому себе» решить.

:::

Так вот, тесты $h_v$​ **рекурсивно** порождают семейство непересекающихся регионов
 ${R_\ell}_{\ell\in V_{\text{leaf}}}\subset\mathcal X$ (гипер‑прямоугольников при осевых разбиениях), причём

$$
\mathcal X=\bigsqcup_{\ell\in V_{\text{leaf}}}R_\ell
$$

,что значит, что объединение всех получившихся регионов и формирует пространство признаков. На правом верхнем рисунке 2, а также на правом рисунке 4 и указаны {простые} примеры такого разбиения.

#### **2.1.5. Предсказательная функция дерева**

Помня, что дерево задается $T=(V,E,r)$, определим отображение

$$
f_T:\mathcal X\longrightarrow\mathcal Y,\qquad f_T(x)=\sum_{\ell\in V_{\text{leaf}}} c_\ell\,\mathbb I(x\in R_\ell)
$$

Иначе говоря, **кусочно-постоянная функция** $f_T$ возвращает метку того листа, в который попал объект $x$ при нисходящем обходе от корня. Функция $f_T$ будет многомерным обобщением центрального рисунка 4, а также той самой функции из правого нижнего рисунка 2, о которой мы говорили. 


:::info
В случае с деревом классификации с двумя возможными классами, $c_\ell$ может принимать значения вероятности одного из классов, в каждом листе дерева $\ell\in V_{\text{leaf}}$ (см. рисунок 4).

:::

Проводя параллель с линейной регрессией, наша обученная ступенчатая функция $f_T$ на самом деле выполняет ту же роль, что и обученная регрессия $\hat{y}=\hat{\beta_0} + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + ..…$Таким образом, в линейной регрессии, имея входные данные по какому-то наблюдению, мы можем подставить эти данные в обученную регрессию (“подставить значения иксов”) и получить *оценку* целевой переменной $\hat{y}$. Точно так же в алгоритме деревьев, имея данные по наблюдению, мы можем посмотреть, в какой регион в пространстве признаков попадает данное наблюдение, и из этого оценить значение “игрика”, которое может принимать это наблюдение (подставить икс в $f_T(x)$ и посчитать значение функции).

Конечная цель древесного алгоритма достигнута – мы обладаем ступенчатой функцией, которая оценивает (предсказывает) значения “игриков”, полагаясь на значения “иксов”. Однако на протяжении всего вышеописанного, мы все еще не уточняли, а как, собственно, дерево решений обучается на существующих данных? Другими словами, какие конкретно булевы функции присваиваются внутренним вершинам (2.1.2), и какие значения присваиваются каждой терминальной вершине (2.1.3)?

### **2.2. Обучение дерева решений**

#### **2.2.1. Основы**

Формально, обучение дерева решений на данных выборки – процесс, целью которого является **максимизация какого-то функционала качества** (или минимизация какого-то функционала ошибки) **для нахождения оптимального набора параметров**. Но если, например, в линейных моделях очевидно, что является множеством параметров (те самые “бэты”), то что такое параметр в дереве решений? На деле, параметрами в этом алгоритме выступают

- **Признаки**, по которым происходит деление региона пространства признаков на две части (признаки, по которым булева функция внутри каждой внутренней вершины делит эту вершину на две под-вершины, см. 2.1.2);
- **Пороги**, по которым вышеобозначенные признаки делятся на две части (2.1.2);
- **Предсказания** в каждом из листьев (2.1.3).

Проще говоря, наша задача минимизировать какой-то функционал ошибки посредством разбиения пространства признаков на прямоугольные регионы и присвоения каждому региону какое-то одно значение (оценку) целевой переменной.

 ![](/api/attachments.redirect?id=685d9ae3-857c-4a28-b4ec-7639b44887f9 "aspect=1")

*Рисунок 5: Деревья регрессии: функции предсказаний целевой переменной* $y$ *по данным о               признаке* $x$*. Источник: Лекция по Решающим деревьям, Центральный Университет,                                                                                  магистратура.*

Взглянем на рисунок 5. Мы обучили два дерева регрессий с глубиной 1 и 2. Первое дерево разбивает признак $x$ в значении 0.22, и всем объектам, у которых $x < 0.22$, предсказывает значение $\hat{y} = -2.9$, а всем остальным объектам присваивает $\hat{y} = 0.2$. Второе же дерево сначала разбивает признак $x$ в том же значении 0.22, и потом каждый из двух получившихся регионов снова разбивает в точках 0.1 и 0.8, после чего каждому из четырех регионов (листьев) присваивает **по одному константному** значению $\hat{y}$. Таким образом, мы сможем использовать эти обученные деревья для предсказания $\hat{y}$ на новых данных – получив новый объект $x = 0.5$, предсказания значения целевого признака у этого объекта по этим двум деревьям будут $\hat{y} = 0.2$ и $\hat{y} = 0$. Похожий пример ты можешь увидеть на рисунке 6.

На этом примере мы убедились, что целью обучения дерева является нахождение порогов, по которым мы разбиваем признаки (и определение самих признаков, которые мы разбиваем), а также присваивание каждому из получившихся регионов какого-то константного предсказания $\hat{y}$. 

 ![](/api/attachments.redirect?id=cb096dd8-275d-4fc3-9a20-8757693e4a95 "aspect=1")

                               *Рисунок 6: Еще одно дерево регрессии. Источник: scikit-learn,                                                                       <https://scikit-learn.org/stable/modules/tree.html>*

Мы уже выяснили, что древесная модель является **непараметрическим алгоритмом**, что означает, что параметры в этой модели заранее не фиксируются, и их количество может достигать больших значений (больше данных → больше параметров). Действительно, так и получается – чем больше данных мы имеем, тем больше будет разбиений пространства признаков, и тем больше значений $\hat{y}$ нам придется присваивать каждому региону.

Так как же в итоге подобрать такие сплиты переменных и обучить оптимальное дерево с хорошей предсказательной способностью на новых данных? Первая мысль, которая может прийти в голову, это подобрать такие сплиты, которые *минимизировали бы лосс на обучающих данных* (как, например, мы делали в линейной регрессии, когда минимизировали MSE). Однако, в таком случае, мы сразу натыкаемся на проблему: как уже было сказано, дерево решений, в отличие от линейной регрессии, это непараметрическая модель, что означает, что дерево в результате обучения может оказаться **неограниченно гибким.** Таким образом, при цели в минимизации обучающей ошибки, дерево может обучиться до той степени, когда каждое конкретное наблюдение находится в отдельном регионе (количество листьев = количество наблюдений). Хотя такая стратегия и приведет к **нулевой обучающей ошибке**, она покажет **очень высокую тестовую ошибку**, что будет говорить о крайне слабой способности предсказывать значения на новых данных (это еще называется **обобщающей способностью** алгоритма). Это происходит из-за очень высокой дисперсии модели, подробнее мы коснемся этой темы в главе 4.

С другой стороны, можно поставить цель минимизации лосса модели *при каком-то условии*. Например, мы можем целиться на такое разбиение пространства признаков, при котором лосс минимизируется для какого-то заранее зафиксированного количества листьев дерева (например, подбираем такое дерево, которое дает минимальный лосс среди всех деревьев с десятью листьями). В таком случае, если мы имеем дело с деревом регрессии и определяем лосс как квадратичную ошибку, нашей задачей окажется

$$
\min_{R_1, R_2, \dots, R_J} \sum_{j=1}^{J} \sum_{i \in R_j} (y_i - \hat{y}_{R_j})^2 \qquad\text{,for}\; J = 10
$$

где

$$
\hat{y}_{R_j} = \operatorname{ave}(y_i \mid x_i \in R_j).
$$

То есть, если каждый регион на пространстве признаков имеет одно предсказанное значение $\hat{y}_{R_j}$, то минимизироваться общая квадратичная ошибка на всех данных будет только в случае, если $\hat{y}_{R_j}$ является **средним арифметическим** целевой переменной в каждом регионе. Строго математически, это происходит потому, что наименьшим вторым моментом случайной величины является второй центральный момент, или дисперсия (но мы не будем в это углубляться).

Хотя вышеуказанный **наивный метод обучения дерева** является теоретически оптимальным, он крайне трудно реализуем – из-за своей дискретной структуры и непостоянного количества параметров, деревья решений нельзя продифференцировать по параметрам и найти с помощью градиентного спуска {хотя бы локальный} оптимум (как мы делали с линейной регрессией). Только представь – для каждого разбиения первого признака, надо смоделировать разбиение второго признака, а для каждого разбиения первого и второго признаков, надо смоделировать разбиение третьего признака и тд. – даже в случаях с категориальными фичами (уже не говоря о количественных), это очень быстро ведет к комбинаторному взрыву. 


:::info
Таким образом, поиск такого дерева — **NP-полная задача**, то есть человечеству пока неизвестны способы решить её за полиномиальное время. 

:::

Из-за сложностей в нахождении глобального минимума функционала ошибки, мы можем рассмотреть два альтернативных, хотя и неидеальных, но хорошо показавших себя на практике метода:

- Применить **жадный алгоритм (greedy algorithm).** Жадность заключается в максимизации метрики (минимизации лосса) **на каждом сплите**, то есть на каждом разбиении узла дерева наша задача **пошагово** максимизировать качество модели.
- **Оптимизировать** вышеуказанный наивный метод обучения, который можно ускорить и асимптотически, и в константу раз.

Сфокусируемся на первом методе, второй рассматривать в рамках недели не будем.

В рамках жадного **рекурсивного бинарного разбиения** (обсуждали выше), математически, наша задача на каждом разбиении дерева регрессии/классификации максимизировать функционал качества

$$
Q(R, j, t) = H(R) - \left (\frac{|R_\ell|}{|R|} H(R_\ell) + \frac{|R_r|}{|R|} H(R_r)\right)
$$

подобрав оптимальные параметры на текущем сплите:

$$
(j, t) = \argmax_{j, t} \ Q(R, j, t)
$$

Обозначения в верхних двух выражениях:

- $R$ – выбранный для следующего сплита регион пространства признаков;
- $j$ – индекс признака, по которому происходит деление региона;
- $t$ – порог, по которому происходит деление признака;
- $Q(R, j, t)$ – функционал качества (метрика);
- $H(•)$ – **мера неопределенности (impurity measure)**, затронем далее;
- $R_\ell$  – левый регион после разделения родительского региона, аналогично с правым регионом;
- $|•|$ – количество наблюдений в конкретном регионе.

**Мера неопределенности** (по сути, функционал ошибки) региона показывает, насколько объекты внутри региона “не похожи друг на друга”:

$$
H(R) = \min_{c \in Y} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} L(y_i, c)
$$

,где $c$ – наше константное предсказание, которое может быть вещественным числом (для ответов регрессии и меток класса) или вектором вероятностей всех классов внутри региона (только в задачах классификации). 

 ![](/api/attachments.redirect?id=465bd5ac-4edb-4f67-91fd-30d0987ea206 "aspect=1")

*Рисунок 7: Разбиения пространства с меньшей неопределенностью (слева) и с большей                             неопределенностью (справа). Источник: лекции магистратуры ЦУ*

В случае с проблемой классификации, неопределенность максимизируется, если внутри региона количество объектов каждого класса равно, и минимизируется, если внутри региона присутствуют объекты только одного из классов (см. рисунок 7). Если же мы имеем дело с проблемой регрессии, неопределенность увеличивается с ростом разброса (например, дисперсии) объектов. Разные меры неопределенности для регрессий и классификаций мы будем изучать ниже.

Таким образом, $H(R)$ –  мера неопределенности в родительском регионе, а $\frac{|R_\ell|}{|R|} H(R_\ell) + \frac{|R_r|}{|R|} H(R_r)$  – общая **взвешенная (нормированная)** мера неопределенности в двух получившихся после разбиения регионов. Зачем нужна нормировка неопределенностей? Предположим, мы просто считаем сумму $H(R_\ell) + H(R_r)$, а веса обоих дочерних регионов равны. В таком случае, наш критерий начнёт переоценивать «фейковые» сплиты, которые делают один из листов крошечным, но абсолютно чистым. 


:::info
**Приведем пример.** Задача бинарной классификации, мы хотим поделить узел дерева на два подузла. В родительском узле — 100 объектов, соотношение классов – 50/50.

*Сплит A*: влево уходит один идеально чистый объект (соотношение классов – 100/0), вправо — 99 объектов со всё тем же разбиением ≈50/50.
*Сплит B*: делит выборку пополам, в каждом подузле соотношение классов объектов 70/30.

Интуитивно мы понимаем, что мера неопределенности чистого (левого) листа из одного объекта в сплите А равна нулю, а неопределенность у правого листа из того же сплита больше, чем неопределенность обоих листов из сплита В, так как разбиение 50/50 является более зашумленным, чем 70/30.

Предположим, что мы все-таки посчитали меры неопределенностей для обоих сплитов, и получили $H(R_\ell)=0$ и $H(R_r)=0.5$ в случае сплита А, и $H(R_\ell)=H(R_r)=0.42$ в случае сплита В (в дальнейших главах мы подробнее разберем, как это рассчитывается). 

Без нормировки мы сравниваем $H(R_\ell)+H(R_r)$ для обоих сплитов:

- А даёт $0+0.5=0.5$;
- B даёт $0.42+0.42=0.84$.

Алгоритм «подумал бы», что А круче (меньше мера неопределенности).
А теперь попробуем применить нормировку:

- А → $0.01 \cdot 0 + 0.99 \cdot 0.5 = 0.495$;
- B → $0.5\cdot 0.42 + 0.5 \cdot 0.42 = 0.42$.

Теперь выигрывает действительно полезный сплит B. Так что нормировка спасает нас от ловушки «чистого одноэлементного листика» и делает разные сплиты **сопоставимыми по масштабу**.

:::

Теперь разберемся, в чем же в итоге заключается наша цель. Мы поняли, что максимизация функционала качества $Q$ происходит при увеличении **разрыва** между критерием неопределенности до разбиения региона и после. 

**__Наша задача – подобрать такой сплит региона, который сильнее всего уменьшит меру неопределенности модели на этом шаге__**. Простыми словами, нам надо подобрать такое разбиение, которое как можно точнее **сгруппирует** данные на два получившихся региона.

**__Параллельно с этим, для каждого региона необходимо подобрать константное предсказание__**. Обычно в задачах дерева регрессий и квадратичной меры неопределенности, за константное предсказание мы выбираем среднее арифметическое значений целевой переменной по всем наблюдениям внутри региона $c = \operatorname{ave}(y_i \mid x_i \in R_j)$, так как именно среднее по выборке минимизирует сумму квадратов ошибок. Однако другие меры неопределенности предполагают другие статистики (например, медиану), а в задачах классификации обычно выбираются совсем другие, нечисловые, характеристики (об этом ниже).

 ![](/api/attachments.redirect?id=3b17da7f-ed41-4054-be74-d01588227e5a "aspect=1")

            *Рисунок 8: Рост дерева в ширину. Источник: datascience.stackexchange, <https://datascience.stackexchange.com/questions/26699/decision-trees-leaf-wise-best-first-and-level-wise-tree-traverse#:\~:text=,3>*

Теперь понятно, что в первую очередь для каждого региона надо подобрать такой сплит, который будет минимизировать разброс внутри этого региона. Напрашивается вопрос – как конкретно выглядит пошаговая структура построения дерева. А именно, __как мы выбираем, какой именно (следующий) регион надо “сплиттить”__? Для этого есть несколько стратегий.

1. Рост дерева в глубину (сверху-вниз) – разбиваем корень на два узла, далее берем один из узлов (пусть левый), и разбиваем его на два узла, далее берем один из двух конечных узлов (пусть снова левый), и разбиваем на два узла и так далее, до тех пор, пока получившиеся регионы не получится разбивать дальше, и они станут листьями (например, если в каждом регионе останется по одному наблюдению). Далее идем по дереву “наверх”, и раскрываем ближайшую вершину, которая не был раскрыта. В таком же духе, раскрываем ее до тех пор, пока она не превратится в лист. И так далее. В теории графов, это называется **обходом графов в глубину (DFS)**.
2. Рост дерева в ширину (слева-направо) – разбиваем корень на два узла, далее разбиваем левый узел на два узла, и правый узел на два узла – получаем четыре узла. Далее раскрываем каждый из этих четырех узлов еще на два узла. Идем, обычно, слева направо (см. рисунок 8). Такой подход называется **level-wise tree growth**, а в теории графов – **обходом графов в ширину (BFS)**. Также этот подход используется во многих классических методах построения деревьев решений, например, в CART и C4.5.
3. Рост дерева по наилучшим узлам (**best-first**) – на каждом шаге выбирается **регион, разбиение которого даст наибольший выигрыш** **глобально**. В отличие от двух методов выше, здесь алгоритм смотрит на **все листья, доступные для разбиения**, и выбирает среди них тот, где потенциальное улучшение качества максимальное​. Таким образом, дерево растет не строго по уровням или глубине, а в порядке убывания информационного выигрыша (см. рисунок 9). Этот метод также называется **leaf-wise tree growth**, и он широко используется в бустинговых методах, которые мы будем разбирать на следующих неделях.

 ![](/api/attachments.redirect?id=1a6b60cc-0ada-4825-8d63-a82da068198e "aspect=1")

*Рисунок 9: Рост дерева по наилучшим узлам. На каждом шаге, максимизируется **общее**             качество модели. Источник: datascience.stackexchange, <https://datascience.stackexchange.com/questions/26699/decision-trees-leaf-wise-best-first-and-level-wise-tree-traverse#:\~:text=,3>*


:::info
Стоит уточнить, что в случае leaf-wise growth, нашей задачей на каждом шаге будет максимизация $(R, j, t) = \argmax_{R, j, t} \ Q_{best}(R, j, t)$, где $Q_{best}(R, j, t) = Q(R, j, t) * |R|$. Здесь, множитель $|R|$ будет играть роль нормализации – так как теперь нам нужно будет выбрать лучший сплит среди **всех** регионов, необходимо будет прирост качества в каждом из регионов нормализовать по количеству наблюдений в этом регионе. Например, если прирост качества при разбиении первого региона оказался 10, а прирост качества при разбиении второго 5, но количество наблюдений в первом регионе в 20 раз меньше, чем во втором регионе, то логично предположить, что прирост качества при разбиении второго региона все же окажется более ценным для обучения модели. 

:::

Все три метода последовательного построения дерева в конце концов приводят к идентичным результатам, если целью является построение полного и максимально (насколько это возможно) глубокого дерева. Однако мы помним, что дерево решений – алгоритм, который очень легко **переобучается** на существующих данных. При построении полного дерева, есть высокий риск того, что дерево будет ловить “шум” в данных, то есть попросту переобучится на обучающей выборке и утратит обобщающую способность. Чтобы этого избежать, были придуманы разные методы, которые позволяют **ограничивать** гибкость модели. Например, эти методы включают **стоп-критерии**, или раннюю остановку обучения дерева по заданным критериям (например, остановить рост дерева, если количество листьев превысило 20). И тут, для разных критериев остановки, уже **будет иметь значение**, какой из трех методов построения дерева мы выбираем. Подробнее о контроле переобучения дерева в главе 5.

#### **2.2.2. Обучение дерева регрессии**

Вернемся к анализу функционала качества $Q$ и меры неопределенности $H$ (будем называть ее информативностью). Мы знаем, что наша задача – минимизировать информативность → максимизировать качество на каждом сплите региона. Однако очевидно, что определение информативности (усредненного функционала ошибки) напрямую зависит от типа задачи, которую мы решаем: для регрессии лоссы будут определяться иначе, нежели чем для классификации. Начнем с разбора мер неопределенности в задачах регрессии.

Мера информативности напрямую зависит от функционала ошибок:

$$
H(R) = \min_{c \in Y} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} L(y_i, c)
$$

Самый применяемый функционал ошибки в задачах регрессии – квадратичная ошибка:

$$
L(y_i, c) = (y_i - c)^2
$$

В таком случае, неопределенность внутри региона будет измеряться среднеквадратичной ошибкой (Mean Squared Error, MSE):

$$
H(R) = \min_{c \in Y} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} (y_i - c)^2
$$

Мы знаем, что среднее арифметическое – статистика, которая минимизирует MSE:

$$
H(R) = \frac{1}{|R|} \sum_{(x_i, y_i) \in R} (y_i - \frac{1}{|R|} \sum_{(x_j, y_j) \in R} y_j)^2 = \frac{1}{|R|} \sum_{(x_i, y_i) \in R} (y_i - \bar{y})^2
$$

Таким образом, мера неопределенности при квадратичной ошибке – это **дисперсия**, которая и служит показателем разброса данных внутри региона. Получается красивая картинка: оценка значения в каждом листе — это среднее, а выбирать сплиты надо так, чтобы сумма дисперсий в листьях была как можно меньше.

Однако квадратичный функционал ошибки не единственный, который можно применить для поиска оптимальных сплитов.


:::tip
__Информация__ __со звездочкой__: на самом деле, выбор функционала ошибки не случаен, а зависит от того, какой *функционал условного распределения* $Y | X$ мы хотим оценить. Если наша цель – оценить истинное математическое ожидание генерирующих данные условных распределений $\mathbb{E}(Y|X)$, мы будем ставить целью минимизацию квадратичной ошибки, так как, как мы уже заметили, именно такая постановка задачи ведет к оценке мат. ожидания в виде средних арифметических. Однако мы необязательно можем интересоваться истинным мат. ожиданием. Например, нам может быть интересна истинная медиана условных распределений $Med(Y|X)$, и в таком случае мы будем определять лосс как абсолютную ошибку, так как именно медиана данных внутри региона будет минимизировать MAE. Подробнее об этом в главе 4.

:::

Рассмотрим другой лосс, например, абсолютную ошибку:

$$
L(y_i, c) = |y_i - c|
$$

И тогда задача сводится к минимизации среднеабсолютного отклонения (Mean Absolute Error, MAE) от медианы:

$$
H(R) = \frac{1}{|R|} \sum_{(x_i, y_i) \in R} |y_i - MEDIAN(Y)|
$$

,так как именно медиана значений внутри региона минимизирует абсолютную неопределенность.

Прежде чем переходить к анализу деревьев классификации, давай разберемся с тем, как построить дерево регрессии в Python. Для этого даже не придется писать дерево с нуля (хотя в одном из семинаров мы и это попробуем), ведь есть библиотека scikit-learn, где уже прописан алгоритм обучения деревьев. Осталось только подобрать гиперпараметры.

```python
from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor(criterion='squared_error', # критерий расщепления
                                            # «squared_error» / «absolute_error»
     splitter='best',               # разбиение  «best» / «random»
     max_depth=None,                # допустимая глубина
     min_samples_split=2,           # минимальная выборка для разбиения
     min_samples_leaf=1,            # минимальная мощность листа
     min_weight_fraction_leaf=0.0,  # аналогично с весом
     max_features=None,             # #признаков для нахождения разбиения
     random_state=None,
     max_leaf_nodes=None,           # допустимое число листьев
     min_impurity_decrease=0.0,     # порог изменения «зашумлённости»
     ccp_alpha=0.0)                 # для подрезки

model.fit(X, y)
```

Такие гиперпараметры, как `max_depth, min_samples_split, min_samples_leaf` и другие, служат как раз с целью предотвращения переобучения дерева (подробнее затронем в главе 5).


:::info
Стоит упомянуть, что sklearn.tree использует нормированный функционал качества каждого сплита: $Q(R, j, t) = \left(H(R) - \left (\frac{|R_\ell|}{|R|} H(R_\ell) + \frac{|R_r|}{|R|} H(R_r)\right)\right) * \frac{|R|}{N}$. Это может пригодиться при подборе гиперпараметра `min_impurity_decrease`.

:::

#### **2.2.3. Обучение дерева классификации**

Нашей задачей остается на каждом шаге подбирать такой сплит, который бы максимизировал разницу между зашумленностью (неопределенностью) родительского региона, и взвешенной суммой зашумленностей двух дочерних узлов. В деревьях регрессии, эта зашумленность измерялась в мерах среднеквадратичной/среднеабсолютной ошибок, что не могут использоваться в задачах классификации.

Для начала, определим пропорцию наблюдений класса $k$ в каком-то регионе $R$:

$$
\hat{p}_{k} = \frac{1}{|R|} \sum_{x_i \in R} \mathbb I(y_i = k)
$$

Мера неопределенности формулируется так же

$$
H(R) = \min_{c \in Y} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} L(y_i, c)
$$

 ![](/api/attachments.redirect?id=87bbf15a-0190-4300-8524-4782c3436d93 "aspect=1")

     *Рисунок 10: Зависимость мер неопределенности от пропорции первого класса в регионе.           Двухклассовая классификация. Энтропия нормализована. Источник: ESL; Hastie, Tibshirani*

##### **__i. Misclassification error__**

Определим функцию потерь как **0-1 loss function**:

$$
L(y_i, c) = \mathbb{I}[y_i \ne c]
$$

Этот лосс присваивает единицу всем неправильным предсказаниям, и ноль всем правильным.

Мерой неопределенности здесь станет 

$$
H(R) = \min_{c \in Y} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} \mathbb{I}[y_i \ne c]
$$

Здесь $c$ – это конкретный класс предсказания. Очевидно, что предсказанием (классом), которое будет минимизировать неопределенность в этом случае, станет **мода** $c = k^* = \arg\max_k \hat{p}_{k}$:

$$
H(R) = \frac{1}{|R|} \sum_{(x_i, y_i) \in R} \mathbb{I}[y_i \ne k^*] = 1 - p_{k^*}
$$

Эта мера неопределенности называется **misclassification error**. 

**Таким образом**, если мы определяем функционал потерь как 0-1 лосс, то минимизироваться мера неопределенности (средний лосс) будет в том случае, если **для региона классом предсказания будет самый часто встречающийся класс в этом регионе**. Проще говоря, дерево классификации с misclassification error неопределенностью будет стремиться создавать такие регионы, которые будут максимизировать долю самого часто встречающегося класса внутри каждого региона. На рисунке 10 (двухклассовая классификация) видно, что misclassification error минимален в случаях, когда пропорция наблюдений одного класса минимизируется, а другого класса максимизируется. И наоборот - максимум зашумленности достигается в точке $\hat{p_1} = \hat{p_2} = 0.5$.

Например, в случае с двумя классами, если выбор будет стоять между

- Сплит 1: Первый регион (60,40), второй регион (30,40) по количеству наблюдений;
- Сплит 2: Первый регион (80,20), второй регион (10,60) по количеству наблюдений,

тогда дерево с 0-1 лоссом примет решение в пользу второго сплита, так как именно второй сплит будет максимизировать вероятности самых частых классов.

Действительно, misclassification error приводит к тому, чтобы создавать наиболее “чистые” регионы с наименьшим количеством разнородности. Несмотря на свою простоту, эта мера зашумленности редко используется на практике. Все из-за того, что misclassification error фокусируется только на вероятностях одного определенного класса, не принимая во внимание весь вектор вероятностей по всем классам. Более того, misclassification error – невыпуклая и негладкая функция, что значительно усложняет процесс оптимизации и обучения.

##### **__ii. Gini Index (Критерий Джини)__**

Разберем пример. Дерево выбирает между двумя сплитами

- Сплит 1: Первый регион (300,100), второй регион (100,300) по количеству наблюдений;
- Сплит 2: Первый регион (200,400), второй регион (200,0) по количеству наблюдений.

Посчитаем взвешенный misclassification error для обоих сплитов:

$$
\frac{|R_\ell|}{|R|} H(R_\ell) + \frac{|R_r|}{|R|} H(R_r) = \frac{400}{800} * (1 - \frac{300}{400}) + \frac{400}{800} * (1 - \frac{300}{400}) = 0.25
$$

$$
\frac{|R_\ell|}{|R|} H(R_\ell) + \frac{|R_r|}{|R|} H(R_r) = \frac{600}{800} * (1 - \frac{400}{600}) + \frac{200}{800} * (1 - \frac{200}{200}) = 0.25
$$

Взвешенные misclassification errors для обоих сплитов **равны,** хотя второй сплит в среднем генерирует более “чистые” регионы. Один только регион (200,0) уже говорит о, вероятно, хорошем разбиении узла. Как мы уже обсуждали, эта мера зашумленности недостаточно чувствительна ко всем анализируемым вероятностям.

Потому есть необходимость в других мерах неопределенности для задач классификации. Следующие две меры, которые мы будем разбирать, основываются на лоссах, **аппроксимирующих** 0-1 лосс, и соответственно являющихся **суррогатными функциями потерь (surrogate loss functions)**.

Первая такая мера – **критерий Джини**. Эта мера неопределенности основывается на **метрике Бриера (Brier score)**:

$$
BS = \frac{1}{N} \sum_{t=1}^{N} (f_t - o_t)^2
$$

,где $f_t$ – вероятность предсказания какого-то класса у объекта, а $o_t$ – фактическое значение целевой переменной объекта, $N$ – количество объектов. Если, например, $f_t = 100 \%$, а $o_t=0$, то метрика Бриера достигает максимального значения, так как предсказание оказалось абсолютно неверным. Таким образом, метрика Бриера уменьшается при улучшении качества предсказания, а соответственно, может использоваться как лосс функция во фреймворке решающих деревьев:

$$
H(R) = \min_{\sum_k c_k = 1} \frac{1}{|R|} \sum_{(x_i, y_i) \in R} \sum_{k=1}^{K} \left(c_k - \mathbb{I}[y_i = k]\right)^2
$$

Здесь, в отличие от случая с misclassification error, $(c_1, c_2, …, c_k)$ – вектор вероятностей классов внутри региона. Можно показать, что оптимальное значение этой метрики, достигается на векторе $c$, состоящем из выборочных оценок частот классов $(\hat{p_1}, \ldots, \hat{p_k}), \quad \hat{p_i} = \frac{1}{|R|} \sum_i \mathbb{I}[y_i = k].$ То есть, по сути, наши оценки вероятностей разных классов в регионе равны эмпирическим частотам этих классов в регионе. Например, если сейчас в регионе 80% наблюдений первого класса и 20% наблюдений второго класса, то все будущие наблюдения, попадающие в этот регион, будут иметь классовое распределение 80-20 (согласно нашей оценке).

Подставив частоты классов $(\hat{p_1}, \ldots, \hat{p_k})$ на место вектора $c$, мы получаем **критерий Джини**:

$$
H(R) = \sum_{k \ne k'} \hat{p}_{k} \hat{p}_{k'} = \sum_{k=1}^{K} \hat{p_k} (1 - \hat{p_k})
$$

Снова взглянем на рисунок 10, где иллюстрируются значения зашумленностей в двухклассовом случае. Мы видим, что критерий Джини – это, по сути, дифференциируемая версия misclassification error, так как строится этот критерий на гладкой функции потерь (для этого и вводится эта суррогатная функция потерь). Таким образом, получается, что критерий Джини лучше походит для задач оптимизации. Так или иначе, критерий Джини также, как и misclassification error, поощряет сплиты, разделяющие пространство признаков на как можно более “чистые” регионы. Однако, в отличие от misclassification error, критерий Джини более чувствителен к изменениям в пропорциях классов в узлах дерева, а потому Джини – один из двух **наиболее часто применяемых на практике методов оценки зашумленности**.

Как мы уже несколько раз разбирали, результатом обучения дерева классификации в конкретном листе может быть как предсказание одного класса (обычно, моды), так и предсказание в виде вектора вероятностей (вектора частот). Интересно, что если наша задача – дать конкретное предсказание в виде одного класса каждому листу, нам необязательно предсказывать моду. Например, мы можем предсказать класс $k$ с вероятностью $\hat{p_k}$ (для этого понадобится применение методов сэмплирования из категориальных распределений). В таком случае, критерий Джини будет иметь интересное свойство – он будет равен мат. ожиданию неправильной классификации каждого отдельного объекта. Более того, если для каждого класса мы присвоим объектам этого класса значение 1, а объектам всех остальных классов значение 0, то в таком случае критерий Джини будет выступать в роли суммы дисперсий среди всех классов (так как дисперсия случайной величины Бернулли и есть $Var(X) = p(1-p)$).

##### **__iii. Entropy (Энтропия)__**

**Энтропия – еще один очень применяемый метод измерения неопределенности**. Мы немного затронем теоретическую базу, прежде чем переходить на практическое применение в решающих деревьях.

В теории информации, **энтропия** случайной величины (или **энтропия Шеннона**) количественно определяет **средний уровень неопределенности** или информации, связанной с потенциальными состояниями переменной или возможными результатами. Она измеряет ожидаемое количество информации, необходимое для описания состояния переменной, с учётом распределения вероятностей по всем возможным состояниям. 

Пусть $X$ — дискретная случайная величина, которая может принимать значения $x$ из множества $\mathcal{X}$ и распределена согласно функции вероятности $p: \mathcal{X} \to [0, 1]$. Тогда **энтропия** определяется как

$$
H(X) := - \sum_{x \in \mathcal{X}} p(x) \log p(x)
$$

,где логарифм обычно имеет основание 2 (и тогда мы имеем дело с **двоичной энтропией**, измеряемой в **битах**). Со статистической точки зрения, можно заметить, что значение энтропии – это мат. ожидание $\mathbb{E}[-\log p(X)]$, которое еще называют **ожидаемым удивлением (expected surprisal)**. Также заметим, что $0\le p(x) \le 1$, а значит $\log_2{p(x)} < 0$, что означает, что в итоге значения энтропии варьируются от нуля до одного: $0 \le H(X) \le 1$. Энтропия принимает бОльшие значения в случаях меньшей определенности, и максимизируется тогда, когда вероятности всех исходов случайной переменной равны, то есть при равномерном распределении (uniform distribution). Большее неравенство вероятностей классов приводит к меньшему значению энтропии.

 ![](/api/attachments.redirect?id=2235678f-a3fc-42c7-ad50-ba2b68e89829 "aspect=1")

*Рисунок 11: Значения энтропии при броске двух смещенных монет. Источник: лекция                                                                              магистратуры ЦУ*

Теперь разберем пример. На рисунке 11 изображены два эксперимента по подбрасыванию “искривленной” монеты в воздух. В первом случае, вероятности выпадения орла и решки более менее равны, а потому значение энтропии близко к максимальному $0.97 \approx 1$. Во втором эксперименте, монета серьезно смещена в сторону выпадения решки, и в 90 % случаев при подбрасывании такой монеты выпадает решка. Значение энтропии, то есть **__ожидаемого удивления от исхода эксперимента__**, в этом случае, конечно, значительно меньше. Все значения энтропии (нормированные, с максимум в 0.5) в двухклассовой классификации ты можешь увидеть на рисунке 10.

Значение энтропии идеально вписывается во фреймворк обучения деревьев классификации, ведь именно этот критерий по определению измеряет неравномерность данных. 

Мы все так же выводим меру неопределенности из среднего значения функционала ошибки. Здесь за функцию лосса выступает **лог-лосс (cross-entropy loss)**, который является отрицательным **лог-правдоподобием (log-likelihood)**, и выводится из задачи максимизации лог-правдоподобия (=минимизации минус лог-правдоподобия):

$$
P(y \mid x, c) = P(y \mid c) = \prod_{(x_i, y_i) \in R} P(y_i \mid c) = \prod_{(x_i, y_i) \in R} \prod_{k=1}^{K} c_k^{\mathbb{I}[y_i = k]}
$$

$$
H(R) = \min_{\sum_k c_k = 1} \left( -\frac{1}{|R|} \sum_{(x_i, y_i) \in R} \sum_{k=1}^{K} \mathbb{I}[y_i = k] \log c_k \right)
$$

, где $c$ – это, как и в критерии Джини, вектор вероятностей классов в регионе.

Оптимизация в виде минимизации Лагранжиана (мы не будем здесь ее расписывать), приводит к тому, что минимизироваться значение минус лог-правдоподобия будет в случае, когда вектор $c$ соответствует частотам классов в листе $(\hat{p_1}, \ldots, \hat{p_k})$, как и в критерии Джини (оба критерия аппроксимируют один и тот же 0-1 лосс, так что это логично). Подставляя значения частот на место вектора $c$ получаем то самое выражение для энтропии:

$$
H(R) = - \sum_{k=1}^{K} \hat{p_k} \log \hat{p_k}
$$

Интересно, что теория информации также определяет **прирост информации (Information Gain)** как уменьшение энтропии, полученное в результате разбиения набора данных по оптимальному кандидату для разбиения:

$$
IG(Y \mid X) = H(Y) - H(Y \mid X)
$$

Это значение показывает, насколько знание $X$ уменьшило неопределенность в $Y$. Это отсылает нас к нашему критерию качества $Q$, который определяется по тому же принципу.

На практике, значения критериев Джини и энтропии для каждого сплита дерева очень схожи, и часто приводят к обучению одного и того же дерева (но не всегда).

Вернемся к примеру, который мы разбирали в секции по misclassification error:

- Сплит 1: Первый регион (300,100), второй регион (100,300) по количеству наблюдений;
- Сплит 2: Первый регион (200,400), второй регион (200,0) по количеству наблюдений.

Тогда, как misclassification error для обоих сплитов равен, критерии Джини и энтропии показывают меньшие значения для второго сплита. Как уже отмечалось, это говорит о более высокой чувствительности к вероятностям разных классов у критериев Джини/энтропии.

Вкратце упомянем, как деревья классификации можно моделировать в Python через использование библиотеки scikit-learn.

```python
from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(criterion='gini', # критерий расщепления
                                                 # «gini» / «entropy»
     splitter='best',               # разбиение  «best» / «random»
     max_depth=None,                # допустимая глубина
     min_samples_split=2,           # минимальная выборка для разбиения
     min_samples_leaf=1,            # минимальная мощность листа
     min_weight_fraction_leaf=0.0,  # аналогично с весом
     max_features=None,             # #признаков для нахождения разбиения
     random_state=3,
     max_leaf_nodes=None,           # допустимое число листьев
     min_impurity_decrease=0.0,     # порог изменения «зашумлённости»
     class_weight=None,             # веса классов («balanced» или словарь)
     ccp_alpha=0.0)                 # для подрезки

model.fit(X, y)
```

На этом мы завершаем разбор разных техник по обучению деревьев регрессий и классификаций. Резюмируем изученное. 

При обучении дерева решений есть два режима: наивный — перебирает все комбинации сплитов и теоретически ищет глобальный максимум, и жадный — строит дерево рекурсивно, в каждой вершине выбирая лучший локальный разрез; в практике почти всегда используем жадный из-за экспоненциальной стоимости полного перебора. Качество любого сплита оцениваем функционалом $Q$, который измеряет, насколько уменьшается неопределённость/ошибка после деления узла. Для регрессии неопределённость обычно меряют среднеквадратичной (MSE) или среднеабсолютной (MAE) ошибкой, а для классификации — misclassification error, индексом Джини или энтропией. Сплит с максимальным выигры­шем по $Q$ выбирается и процесс повторяется, пока не нарушится какой-то стоп-критерий (минимальное число объектов в листе, максимальная глубина и т.д. Про остановку роста поговорим в главе 5). Само дерево можно порождать разными путями (например, «вглубь» или «вширь»); при использовании стоп-критериев, разные методы построения могут выдавать отличающиеся итоговые деревья. 

В сумме: жадный поиск + правильная мера неопределённости дают нам практичный алгоритм, который шаг за шагом превращает исходные данные в иерархию простых правил. Стоит помнить, что все жадные методы редко приводят к теоретически оптимальным деревьям. Однако простота использования и высокая скорость обучения делают эти методы широко применимыми на практике: “Лучше синица в руках, чем журавль в небе”.

### **2.3. Тонкости**

Ты уже знаешь, что такое алгоритм дерева решений и понимаешь, как его обучить на существующих данных. Однако, как и везде, в вопросе обучения и понимания работы деревьев решений есть “подводные камни”, которые мы здесь и упомянем.

#### **2.3.1. Категориальные признаки**

Что для численных, что для категориальных признаков, наша задача при обучении дерева – разделить признак так, чтобы максимизировать разницу между объектами в двух дочерних регионах. В случае с численными признаками все очевидно – нам нужно найти числовой порог, который будет “разрывать” признак на две части. Но что делать с номинальными категориальными переменными, которые не делятся по одному числовому порогу? Есть, по сути, две стратегии:

- Отказаться от бинарного разбиения в пользу мульти-сплита: разбить родительский узел с категориальным признаком на $k$ дочерних узлов, где $k$ – количество значений категориального признака. Такой подход может показать достойные результаты, но только в случае, если $k$ – небольшое число. Если же категориальный признак может принимать много значений и $k \gg 0$, такой подход может привести к огромному количеству листьев в обученном дереве.
- Сохранить бинарное разбиение и сравнить функционалы качества для каждого возможного сплита меток на две группы. Например, если качественный признак принимает значения из множества {“A”, “B”, “C”}, сравнить неопределенности сплитов {{“A”, “B”}, {“C”}}, {{“A”, “C”}, {“B”}}, {{“B”, “C”}, {“A”}}, и выбрать сплит, дающий наименьшую общую неопределенность. Однако, согласно **числам Стирлинга второго рода** (комбинаторика moment), число разбиений n-элементного множества на 2 подмножества равно $\left{ \begin{array}{c} k \ 2 \end{array} \right} = 2^{k-1} - 1$, что является экспоненциально взрывающейся последовательностью с растущим $k$. Если, например, качественный признак принимает 100 меток, алгоритму придется сравнить качество $\approx 2^{99}$ сплитов, что представляется крайне ресурсозатратным процессом.

Есть и хорошая новость: существует метод, который позволяет сохранить бинарное разбиение при оптимальной алгоритмической сложности, но только в задачах регрессии или двухклассовой классификации. Разберем этот метод.

В случае бинарной классификации, необходимо **отсортировать** признак по меткам в порядке возрастания/убывания частоты первого класса в метке. Например, сначала идут метки признака с минимальным количеством объектов первого класса, далее – метки со всё бОльшим количеством первого класса и тд. После этого, этот признак можно разбивать так же, как и числовой – используя какой-то порог. Можно доказать, что в случае с мерами зашумленности Джини/энтропии, этот “лайфхак” приводит к тем же сплитам, что и перебор всех $2^{k-1} - 1$ комбинаций разбиений.

В случае регрессии, суть все та же, но теперь мы сортируем метки признака по возрастанию/убыванию среднего арифметического в каждой метке.

В целом, категориальные признаки с большим количеством меток $k$ следует избегать: из-за большого количества возможных разбиений, алгоритм чаще будет предпочитать сплит по этим признакам, что может привести к **серьезному переобучению**.

#### **2.3.2. Пропущенные значения**

Классические алгоритмы деревьев решений (напр., CART) действительно хороши в работе с пропущенными значениями в данных. Но перед тем, как разобраться в механизмах работы с missing data, сначала надо разобраться, какие типы пропущенных данных вообще бывают. Сетап: имеется признак и объекты, значения которых по этому признаку отсутствуют.

- **Missing completely at random (MCAR)** – пропуски в значениях признака полностью случайны и не зависят ни от наблюдаемых, ни от ненаблюдаемых величин (абсолютная независмость от данных). На практике встречается **редко**. Пример: “*Лаборатория.* Партия проб испорчена из‑за сбоя центрифуги, поэтому у **случайного** поднабора пациентов отсутствует показатель — его отсутствие никак не связано с их состоянием”.
- **Missing at random (MAR)** – пропуски зависят только от **полностью наблюдаемых** переменных. Пример: “*Мед‑опрос.* Мужчины реже заполняют анкету с вопросами о депрессии, но **при фиксированном поле «пол» вероятность пропуска не зависит** от реального уровня депрессии”.
- **Missing not at random (MNAR)** – пропуски зависят от **самого скрытого значения** (или других ненаблюдаемых факторов). Пример: “*Доходы в анкете.* Люди с очень высоким доходом чаще пропускают вопрос «Сколько вы зарабатываете?»”. Второй пример: “*Симптоматика.* Пациенты с тяжёлой депрессией с большей вероятностью отказываются заполнять шкалу тяжести”.

Все методы, которые мы предложим далее, работают в MCAR/MAR случаях. В случае MNAR, требуется применение более сложных механизмов, которые, тем не менее, все равно не смогут “безболезненно” (с малой потерей информации) справиться с проблемой неслучайных пропущенных данных.

Наконец, мы переходим к самим методам борьбы с MCAR/MAR пропущенными значениями. В целом, в машинном обучении они выглядят так:

- **Удаление** данных об объекте с пропущенной информацией. Этот метод может использоваться в случаях, когда пропущенных данных не так много. Желателен также MCAR сценарий;
- **Импутация (подстановка)** данных. Например, вместо пропущенных значений по признаку, мы можем подставить среднее/медиану по этому признаку. Однако обычное заменение данных не учитывает факт неопределенности в этих замененных данных. Чтобы учесть неопределенность, мы можем подставить несколько разных значений, обучить несколько моделей, после чего измерить нестабильность предсказаний;
- Если переменная категориальная, мы можем присвоить пропущенным значениям этой переменной **новый класс missing**. Особенно это актуально в ситуациях, когда пропуски имеют системный характер и их наличие несёт в себе определённую информацию. Кстати, это может быть одним из способов проверки сценария MCAR – если класс missing связан со значениями других признаков или целевой переменной, то наш сценарий – точно не MCAR;
- В случае зависимых признаков, мы можем попытаться **смоделировать зависимость** переменной с пропущенными данными от значений других признаков. Например, возможно построение линейной регрессии, которая будет предсказывать значения признака с пропущенными данными, и таким образом позволяющей оценить пропуски в признаке.
- У разных алгоритмов могут быть специальные способы борьбы с missing data.

Касательно последнего пункта, мы можем дополнительно рассмотреть методы, применяемые в классических деревьях решений. Один из таких методов – при обучении дерева, оценивать качество сплита признака с пропусками **без учета** объектов с пропущенной информацией по этому признаку. Далее, если принято решение разбивать этот признак, мы отправляем эти объекты и в левое, и в правое поддерево. При этом, мы присваиваем им веса: $\frac{|R_l|}{|R|}$ и $\frac{|R_r|}{|R|}$ для объектов в левом и правом поддереве. Далее эти веса будут учитываться как коэффициенты при $L(y_i,c)$ в формуле информативности. Более того, при предсказании тестовых данных, если объект не имеет информации по признаку в узле, мы отправляем этот объект и в левое, и в правое поддерево. В конце, мы измеряем конечное предсказание этого объекта как $\hat{y} = \frac{|R_l|}{|R|} \hat{y}_l + \frac{|R_r|}{|R|} \hat{y}_r$, где $\hat{y}_l$ и $\hat{y}_r$ – предсказания листов, в которые попали эти объекты.

Вышеуказанный метод не единственный для борьбы с missing data. В алгоритмах CART и подобных, также часто используются так называемые **суррогатные расщепления (surrogate splits).** Этот механизм предполагает разбивать признаки с пропусками не напрямую, а через использование суррогатных переменных. Другими словами, мы подбираем суррогатный признак, который сильнее всего связан (скоррелирован) с признаком с пропусками, и моделируем сплиты по этому суррогатному признаку. Этот метод также работает только в случаях существования сильной зависимости между признаками. Желателен MCAR/MAR сценарий.

#### **2.3.3. Матрица ошибок (Loss matrix)**

Когда мы учились обучать деревья классификации в секции 2.2, мы негласно предполагали, что точность предсказания каждого класса имеет равностепенную ценность: последствия от предсказания класса 1 классом 2 были равны последствиям от предсказания обратного.

Однако представим сценарий: ты – врач-кардиолог, и у тебя есть данные по разным пациентам (имя, пол, возраст и тд) со знанием того, был ли у каждого конкретного пациента сердечный приступ или нет. Твоя задача – определить зависимость между независимыми признаками и целевой переменной (“Сердечный приступ”), дабы использовать знания об этой зависимости для предсказания риска сердечного приступа у будущих пациентов. Очевидно, что в этом случае предсказать отсутствие сердечного приступа при условии, что он произойдет (false negative) приводит к гораздо более плачевным последствиям, нежели предсказание сердечного приступа при условии, что его не будет (false positive).

В задачах классификации, когда ошибка распределена неравномерно, и ошибиться в предсказании каких-то классов хуже (чревато более серьезными проблемами), чем в предсказании других классов, нам следует ввести соответствующие поправки в обучение и предсказание модели.

Одним из способов учесть неравноценность ошибок является введение **матрицы ошибок** $\mathbf L$ размерностью К х К, где $L_{kk’}$ – значение потери при классификации объекта класса $k$ как класс $k’$. Правильные предсказания не штрафуются: $L_{kk’} = 0$ для $k=k’$. Эту матрицу можно использовать для коррекции разбиений дерева во время обучения, например, внедрив ее в критерий Джини: $\sum_{k \ne k'} L_{kk'} \hat{p}_{k} \hat{p}_{k'}$. По такой же схеме можно изменить критерий энтропии. Стоит упомянуть, что это работает только в случае $K > 2$, а в бинарной классификации мы при обучении просто даём больший вес тем примерам, где ошибка дороже. Конечное предсказание в терминальных вершинах также меняется с моды на $k^* = \arg\min_k \sum_{\ell} L_{\ell k} \hat{p}_{\ell}$.

#### **2.3.4. Важности признаков (Feature importance)**

В деревьях решений (и ансамблях на их основе) модель обучается на множестве признаков $X_1,…,X_p$, но **не все они одинаково влияют на прогноз**. Оценка важности признаков отвечает на два практических вопроса:

1. **Интерпретация.** Какие факторы действительно «двигали» решения модели?
2. **Инженерия.** Какие столбцы можно отобрать, упростить, собрать ещё данных или наоборот — выкинуть без потери качества?

 ![](/api/attachments.redirect?id=471598ec-dc23-4904-9683-e92b9a7ea908 "aspect=0.7034013605442176")

*Рисунок *: Важности признаков по мере процентного уменьшения меры энтропии после деления. Источник: https://cran.r-project.org/web/packages/randomUniformForest/vignettes/VariableImportanceInRandomUniformForests.pdf*

Так как измеряется важность признаков? Посмотрим на один из способов. Вспомним формулу функционала качества, которое измеряет уменьшение в мере неопределенности в результате сплита. Так вот, идея в том, что чем сильнее признак уменьшает неоднородность региона, тем он считается важнее. В итоге, важность признака – {иногда нормированная} сумма уменьшений неоднородностей с помощью этого признака при построении дерева.

В целом, посмотрев на дерево решений, уже можно сделать предварительные выводы о важности признаков: более “высокие” сплиты обычно характеризуют деление более важных признаков, так как именно первоначальные сплиты обычно приводят к наибольшим падениям в неопределенности (но не всегда). Однако **в ансамблевых методах**, которые предполагают построение большого количества деревьев, важности признаков не получится измерить с помощью графиков и рисунков. В таких случаях, полезны будут вычисления, о которых мы написали выше.

В Python, использование аттрибута feature_importances из библиотеки scikit-learn (который использует при расчете метод, указанный нами выше) поможет рассчитать важности признаков:

```python
model = DecisionTreeClassifier()
model.fit(X, y)

# Получить важности признаков
importance = model.feature_importances_

# Можно расписать в виде текста и нарисовать гистограмму
for i, v in enumerate(importance):
    print(f'Feature: {i}, Score: {v:.5f}')
plt.bar([x for x in range(len(importance))], importance)
plt.show()
```

#### **2.3.5. Нестабильность деревьев**

Как мы уже несколько раз обсуждали, деревья решений считаются крайне нестабильным алгоритмом (non-robust), что значит, что малейшее изменение в обучающей выборке может привести к колоссальным изменениям в структуре обученного дерева. На статистическом языке, это говорит о высокой дисперсии (high variance) оценки зависимости между признаками и целевой переменной. В главе 4 мы покажем (и в целом углубимся в эту тему), что высокая дисперсия оценки является крайне нежелательным явлением, которое может приводить к сильному увеличению ошибки предсказания тестовых данных (например, test MSE). Именно из-за высокой вариативности деревьев были разработаны **ансамблевые методы** — они сочетают неплохую предсказательную способность деревьев с возможностью существенно снизить общую дисперсию модели.

На этом мы заканчиваем теоретический разбор алгоритма обучающих деревьев.

## **3. Применение метода решающих деревьев** 

### **3.1. Сильные и слабые стороны деревьев решений**

Обо многих достоинствах и недостатках решающих деревьев мы уже упоминали на протяжении этого лонгрида. В этой секции, мы вкратце обобщим все ключевые моменты, отвечающие на вопрос “Почему, несмотря на все свои ключевые преимущества, деревья решений не так часто используются на практике?”

#### __Преимущества__

- **Интерпретируемость, простота и white-box особенность.** Дерево решений визуально легко представить и понять: каждая внутренняя вершина отражает условие на одном из признаков, а листья — итоговый прогноз. В целом, деревья решений относятся к разряду **white-box моделей**, у которых внутренняя структура и правила принятия решений полностью понятны и прозрачны пользователю. Используя дерево, пользователь может проследить путь от корня до листа («if-then»‑вопрос), что очень важно в задачах, где требуется объяснимость и интерпретируемость (медицина, финансы). На самом деле, в реальном мире, много в каких отраслях высоко ценится интерпретируемость модели. Зачастую, дата аналитики выбирают пожертвовать долей точности предсказания ради интерпретируемости результатов. В итоге, **объяснимость/интерпретируемость являются главными преимуществами деревьев.**
- **Непараметричность метода и отсутствие предположений о распределении данных.** Как мы уже обсуждали, непараметричность деревьев “освобождает нас от оков”, позволяет моделировать зависимости любой сложности и избавляет от большей части предположений (assumptions) о распределении данных, виде зависимости и так далее. Например, в отличие от линейных моделей, деревья не требуют нормальности признаков или линейной зависимости между ними. Более того, как мы уже выяснили, деревья могут работать с любыми типами данных (числовыми, категориальными) без сложной предобработки.
- **Гибкость и возможность преобразований.** Это свойство вытекает из предыдущего и в то же время является одним из главных фичей алгоритма, которое позволяет деревьям легко комбинироваться в ансамбли (**Bagging, Random Forest, Gradient Boosting**), **значительно повышая** качество предсказаний без потери базового поведения.
- **Обработка пропусков.** Алгоритмы деревьев (особенно CART) известны своей способностью по качественной обработке пропущенных значений без использования импутации (подстановки) данных. Как уже отмечалось, многие “деревянные” реализации умеют расщеплять объекты с пропущенными значениями на несколько ветвей, а также вводят механизм суррогатных расщеплений для оценки оптимального расщепления признака с пропусками в данных.
- **Важность и автоматический отбор признаков.** При построении дерева наиболее информативные признаки оказываются ближе к корню, что фактически иллюстрирует важность признаков и реализует implicit **feature selection**.
- **Невысокие вычислительные затраты на обучение и прогноз.** Благодаря жадному (поэтапному) алгоритму построения деревьев, алгоритмическая сложность модели CART относительно невысока и может дополнительно снижаться при использовании различных оптимизаций. Кроме того, прогноз для одного объекта сводится к простому последовательному обходу ветвей, что обеспечивает очень быструю обработку даже в случае глубокого дерева.

#### __Недостатки__

- **Склонность к переобучению (overfitting)** является одной из самых слабых сторон алгоритма, и в то же время следствием его непараметрической природы. Известно, что глубокие деревья при отсутствии сдерживающих ограничений могут идеально подгоняться под шум в тренировочных данных, теряя обобщающую способность на новых примерах. Это ведет к необходимости тщательной настройки гиперпараметров: максимальной глубины, минимального числа объектов в листе, критериев разбиения. Тему контроля переобучения мы затронем в следующих главах.
- **Невысокая точность и «кусочность» пространства решений.** Ключевой недостаток деревьев решений в том, что даже при эффективном контроле переобучения они уступают линейным моделям в задачах с линейными зависимостями и специализированным нелинейным методам (включая нейронные сети) — в задачах с нелинейными зависимостями.
- **Неустойчивость к небольшим изменениям в данных.** Как мы выяснили, это является следствием высокой дисперсии оценок модели, когда небольшие флуктуации тренировочных примеров могут привести к построению совершенно другого дерева. Более того, проблема усугубляется при переобучении на тренировочной выборке.
- **Смещение в сторону признаков с большим числом уровней.** При выборе сплита алгоритм предпочитает категориальный признак с большим количеством уникальных значений (больше возможных разбиений), даже если он менее информативен.
- **Требовательность к объёму данных при большой глубине** также является следствием непараметричности: для стабильного обучения глубоких деревьев требуется много примеров; в малых выборках модель легко подстраивается под шум.
- **Сложность оптимальной структуры:** нахождение глобально оптимального дерева NP‑трудоёмко, поэтому обычно используют жадные алгоритмы (например, CART), которые могут пропускать лучшие и теоретически оптимальные решения.

### **3.2. Деревья VS Линейные модели**

Очевидно, что выбор оптимального алгоритма машинного обучения, способного качественно подстроиться под обучающую выборку и обладающего обобщающей способностью, напрямую зависит от типа зависимости между признаками $X_1, \dots, X_p$ и целевой переменной $Y$. В целом, со статистической точки зрения, одна из наших главных задач – как можно точнее “угадать” вероятностное распределение, которое генерирует данные нашей выборки. Зная это распределение, мы сможем построить теоретически оптимальную модель, ошибка которой будет минимальна. Однако на практике, мы почти никогда не знаем, как выглядит такое распределение, и поэтому наша задача – хотя бы примерно оценить его с помощью имеющейся выборки. В корне неверная оценка изначального распределения чревата очень высокими ошибками на тестовых данных. Такое бывает, когда мы, например, предполагаем линейную зависимость между переменными (чтобы построить линейную модель), хотя на деле эта зависимость явно нелинейна.

 ![](/api/attachments.redirect?id=00d3334e-7bf1-4713-a0f6-41bfd6e2d0cf "aspect=1")

*Рисунок *: Перформанс алгоритмов дерева и линейной модели (напр., логистической регрессии) в двух случаях линейной и нелинейной зависимостей (задача классификации). Источник: ISL; Hastie, Tibshirani*

На рисунке выше изображены два случая с линейной (верхний ряд) и нелинейной (нижний ряд) зависимостями в данных. Можно наглядно увидеть, к каким печальным результатам приводит выбор неверного алгоритма обучения.

Есть и другие критерии, на которые можно опираться при выборе модели:

1. Как только что обсудили, зависимость ближе к линейной → выбираем линейную модель, ближе к ступенчатой → дерево решений;
2. Если признаков намного больше, чем объектов ($p \gg n$), разумнее будет выбрать линейную модель, так как регуляризаторы в линейных моделях могут смягчить переобучение, в то время как дерево решений с огромным количеством признаков рассыпется;
3. Если нужна глобальная интерпретация результатов (какие признаки как именно влияют на целевую переменную) → выбираем линейную модель, если же нужна локальная интерпретация (“Почему этому клиенту отказываем в кредите?”) → лучше подойдет дерево;
4. Если есть необходимость в **экстраполяции предсказаний** → линейная модель подойдет намного лучше. Дерево решений имеет хорошую предсказательную способность только в пределах значений обучающей выборки, в то время, как на данных за этими пределами дерево предсказывает просто константу;
5. При сильных взаимодействиях между фичами → лучше выбрать дерево;
6. При специфических данных, например, при большом количестве категориальных фичей или пропущенных значений, дерево подойдет больше;
7. Если память и скорость алгоритма критичны (например, при большом количестве данных или при online обучении) → выбираем линейную модель. Параметрические модели в целом быстрее непараметрических, так как первые пытаются оценить фиксированное количество параметров;


:::tip
Кстати, в анализе отличий линейных моделей от деревьев решений хотелось бы упомянуть то, что, вообще-то, дерево можно **представить** в виде линейной модели! Вспомним, что линейная регрессия – это модель вида 

:::

$$
f(X) = \beta_0 + \sum_{j=1}^{p} \beta_j X_j
$$


:::tip
В то же время, дерево регрессии можно представить как

:::

$$
f(X) = \sum_{m=1}^{M} \beta_m * \mathbb I(X\in R_m) 
$$


:::tip
Таким образом, дерево представимо линейно: мы можем **заменить** пространство признаков $X_1, X_2, ...$ на признаки $\mathbb I(X\in R_m)$, то есть мы можем считать принадлежность объекта к каждому региону дерева за отдельный признак. Таким образом, сформируется $M$ dummy признаков (принимающих 0-1 значения) для каждого из $M$ регионов, и для каждого из этих признаков $\beta_m$ будет значением целевой переменной на листе соответствующего региона. 

Этот подход позволяет применять линейные модели в случае нелинейных данных, а также понимание этого явления поможет в будущих лонгридах, когда мы будем разбирать принципы работы бустинговых ансамблевых методов.

:::

Таким образом, на этой неделе мы изучили механизм работы разных реализаций алгоритмов деревьев решений, разобрали сильные и слабые стороны этого метода и сравнили его с линейными моделями. На следующей неделе, мы разберемся в таких явлениях, как bias-variance tradeoff и проблема переобучения моделей, после чего мы вернемся к теме деревьев и рассмотрим, как можно избежать оверфиттинга в подобных гибких моделях.

---

## **4. Обобщающая способность, переобучение и сложность модели**

На прошлом занятии мы изучали алгоритм деревьев решений – не самый точный, но зато выдающийся по своей простоте и интерпретируемости классический алгоритм машинного обучения. Теперь мы начинаем новую тему и переходим на совершенно новый блок по изучению сложности разных ML алгоритмов. В следующей главе, мы снова вкратце вернемся к деревьям, но уже в рамках анализа их сложности и обобщающей способности.

Начнем наше обсуждение с мотивации и интуиции. 

В работе с алгоритмами машинного обучения, наша задача, по сути, сводится к двум моментам:

1. **Выбор модели**. На этом шаге мы сравниваем перформанс разных моделей с разными гиперпараметрами (обычно используя валидационную выборку) для выбора модели с наименьшей валидационной ошибкой.
2. **Оценка модели на тестовых данных**. После того, как модель выбрана, мы оцениваем тестовую ошибку (**test error**). **Важно**: мы **не** используем тестовую ошибку в целях подбора лучшей модели! Проверка на тестовых данных служит только для оценки качества модели.

Остановимся на первом пункте. Как мы выбираем модель и от чего мы отталкиваемся при выборе оптимального алгоритма? Очевидно, нашей конечной задачей (для чего вообще ML применяется) является **максимизация какой-то бизнес-метрики**, которая часто совпадает с **минимизацией ошибки модели**. Но если нашей задачей является минимизация ошибки, то почему мы не можем просто построить модель, которая будет **идеально** проходить через “точки” обучающей выборки, как на рисунке 1?

 ![](/api/attachments.redirect?id=bcde922b-5030-410a-925d-fa68ac827eb2 "aspect=0.4532608695652176")

*Рисунок 1: Пример интерполяции по существующим числовым данным. Источник: <https://medium.com/@polluxrey/interpolation-54cf494e07f3>*

В математике, **интерполяция** – это техника восстановления функции по имеющемуся дискретному набору её известных значений. При построении модели, метод интерполяции действительно будет минимизировать, и, по сути, обнулит ошибку на обучающей выборке (**training error**). И все бы казалось отлично, но в чем подвох? 

Стоит помнить, что нашей основной задачей является минимизация **не обучающей, а тестовой** ошибки. В целом, мы строим и подбираем модель машинного обучения для того, чтобы она хорошо предсказывала результаты на будущих, невиданных нами данных. Практика же показывает, что метод интерполяции обучающих объектов приводит к очень высоким ошибкам на тестовой выборке, по сути говоря о плохой **обобщающей способности модели**. Это происходит потому, что у любой выборки, взятой из данных по населению, есть **шум**, характерный только для этой выборки. В то же время, чрезмерно **извилистая/гибкая** модель (как, например, интерполирующая модель) “ловит” этот шум, путая его с истинными зависимостями в данных по населению. Это называется **переобучением (overfitting)** модели на обучающей выборке, и это одна из главных проблем, с которой можно столкнуться в машинном обучении.

В то же время стоит помнить, что и построение чрезмерно **ригидной/стабильной** модели (например, линейной) может обернуться тем, что алгоритм не сможет в достаточной степени подстроиться под реальную зависимость, что приведет к **недообучению (underfitting)**. Другими словами, тут, как и везде, важно сохранение **баланса** и избегание крайностей. Наша цель – как можно точнее уловить истинную зависимость случайных величин, но в то же время не укатиться в чрезмерно дотошное подражание обучающей выборке.

В следующих секциях этой главы, мы рассмотрим тему обобщающей способности моделей машинного обучения с более математической точки зрения, а также в бОльших деталях объясним интуицию этого явления.

### **4.1. Статистические основы**

Начнем с основ, и по мере продвижения будем все больше углубляться в детали.

В этом анализе нам пригодится понимание того, что такое математическое ожидание и дисперсия случайных величин. Ты уже изучал это на курсе по статистике, здесь же мы проведем небольшой recap.

Среднее арифметическое – это сумма элементов дискретного конечного множества чисел, поделенная на количество элементов этого множества. По сути, это ситуация, когда каждый элемент множества имеет одинаковый вес (ценность) – потому мы и делим на количество элементов. 

Взвешенное среднее – то же среднее арифметическое, но теперь каждый элемент имеет свой индивидуальный вес:

$$
{\bar {x}}=\sum \limits _{i=1}^{n}{w_{i}x_{i}}.
$$

где ${\textstyle \sum \limits _{i=1}^{n}{w_{i}}=1}$.

**Мат. ожидание (expectation)** – это обобщение взвешенного среднего на непрерывные бесконечные данные:

$$
 \operatorname {E} [X]=\int _{-\infty }^{\infty }xf(x)\,dx.
$$

где $f(x)$ – это те же веса, но теперь уже в виде вероятностей из непрерывного вероятностного распределения. Интуитивно, мат. ожидание тоже является средним всех элементов множества, но применяется оно только в случаях, когда этих элементов бесконечно много, а само множество несчетно (например, множество вещественных чисел), что делает обычное сложение невозможным, и необходимо использование интеграла. Технически, мат. ожидание называется **первым моментом** случайной величины.


:::info
Стоит уточнить, что здесь оператор $\operatorname {Е}$ считает мат. ожидание по вероятностному распределению случайной величины $X$, и технически он обозначается как $\operatorname{E}_X [X]$. 

:::

**Дисперсия** **(variance)** – это мат. ожидание квадрата отклонения случайной величины от её мат. ожидания. Дисперсия является **мерой разброса**. Интуитивно, дисперсия измеряет, насколько случайная величина в среднем отклоняется от своего среднего, возведенное в квадрат:

$$
\operatorname {Var} (X)=\operatorname {E} \left[(X-\mu )^{2}\right]=\int_{-\infty }^{\infty }{\left(x-\mu \right)}^{2}f(x)\,dx\[4pt]
$$

Дисперсия – это **второй центральный момент** случайной величины $X$. В названии, “второй”, так как степень выражения 2, а “центральный”, так как это момент вокруг мат. ожидания. 

**Стандартное отклонение (standard deviation)** равно квадратичному корню из дисперсии:

$$
\sigma = \sqrt{\operatorname{Var}(X)}
$$

Все три вышеперечисленных оператора являются в основном теоретическими явлениями: на практике они особо не встречаются.

### **4.2. Оценка параметров в статистике**

Как мы уже разобрались в начале этой главы, наша основная задача – построить модель, которая на основании ограниченных данных о населении с максимальной точностью “уловила” бы **истинную** зависимость между признаками и целевой переменной. Со статистической точки зрения, эта модель генерирует **оценку** реальной зависимости. А как сгенерировать наиболее удачную оценку зависимости? Для этого тебе нужно будет вспомнить материал, который ты проходил на курсе по статистике.

В целом, статистическая теория оценивания отвечает на фундаментальный вопрос: как на основе ограниченных и случайных данных сделать обоснованные выводы о параметрах распределения или модели, лежащей в основе этих данных. По сути, на практике мы почти никогда не знаем, как выглядит генеральная совокупность данных. Все, что у нас есть – это какая-то выборка из той самой совокупности. Теория оценивания помогает нам найти «наилучшие» способы приближённо определить неизвестные нам параметры генеральной совокупности. В нашем случае, эти параметры и будут задавать искомую нами зависимость между $X$ и $Y$.


 ![](/api/attachments.redirect?id=bceea8ac-1738-4f8a-b501-d2ecc15779e7 "aspect=1")

*Рисунок 4: Два нормальных распределения двух оценок параметра.* 

Еще раз: в машинном обучении, мы хотим наиболее точным образом **оценить** реальную зависимость между переменными. Давай посмотрим, как в классической статистике измеряется точность оценки какого-то параметра.

Взглянем на рисунок 4, на котором изображены нормальные распределения двух оценок $\hat{\theta_1}$ и $\hat{\theta_2}$ какого-то параметра $θ$. Как ты уже знаешь, мы получаем эти распределения через генерацию оценок на каком-то количестве выборок из населения. Мы видим, что первая оценка несмещенная (**unbiased**), но с высоким разбросом (**high variance**), а вторая оценка смещенная, но более точная и плотнее сконцентрирована вокруг истинного параметра. Какая из этих оценок лучше?

Для того, чтобы ответить на этот вопрос, необходимо сначала определить функцию потерь, по которой мы сравниваем оценки. Возьмем самый распространенный квадратичный лосс:

$$
L(\theta, \hat{\theta}) = (\theta - \hat{\theta})^2
$$

В таком случае, нашей задачей будет выбрать такую оценку, которая бы выдавала меньшую среднеквадратичную ошибку. То есть, нам нужно выбрать такую оценку, которая по всем выборкам (для всех $\hat{\theta}$) выдает **в среднем** меньшую квадратичную дистанцию от истинного параметра. Давай разберемся, из чего состоит среднеквадратичная ошибка (Mean Squared Error) оценки параметра:

$$
{\displaystyle {\begin{aligned}\operatorname {MSE} (\hat{\theta})&=\operatorname {E} [(\hat{\theta}-\theta )^{2}]=\operatorname {E} [(\hat{\theta}-\operatorname {E} [\hat{\theta}]+\operatorname {E} [\hat{\theta}]-\theta )^{2}]\[5pt]&=\operatorname {E} [(\hat{\theta}-\operatorname {E} [\hat{\theta}])^{2}]+2\operatorname {E} [\hat{\theta}-E[\hat{\theta}]](\operatorname {E} [\hat{\theta}]-\theta )+(\operatorname {E} [\hat{\theta}]-\theta )^{2}\[5pt]&=\operatorname {E} [(\hat{\theta}-\operatorname {E} [\hat{\theta}])^{2}]+(\operatorname {E} [\hat{\theta}]-\theta )^{2}\[5pt]&=\operatorname {Var} (\hat{\theta})+(\operatorname {E} [\hat{\theta}]-\theta )^{2} = \operatorname {Var}(\hat{\theta}) + \operatorname {Bias}^2 (\hat{\theta}) \end{aligned}}}
$$

**Среднеквадратичная ошибка состоит из** **суммы дисперсии и квадратичного смещения оценки**! Действительно, чем сильнее оценка разбросана и чем дальше “центр” оценки от реального параметра, тем хуже эта оценка предсказывает значение истинного параметра. Если $\operatorname {Bias} (\hat{\theta})=0$, то есть если оценка несмещенная, то ее качество полностью зависит от ее дисперсии, то есть разброса вокруг истинного параметра. Среди двух несмещенных оценок лучшим выбором будет та, что с меньшей дисперсией. В случае с рисунком 4, необходимо оценить, действительно ли ненулевое смещение второй оценки “перекрывается” значительно меньшей дисперсией.

### **4.3. Оценка параметров в ML, Bias-Variance-Noise разложение и переобучение**

Как обсуждение выше связано с нашим стремлением найти настоящую зависимость между переменными? Дело в том, что модель, которую мы будем строить, оценивает значение $Y$ в **каждой точке** $X$ – другими словами, для каждой точки $x_i$ мы пытаемся оценить реальный параметр, где параметром будет выступать истинное неизвестное значение $y_i$. Нашей оценкой будет $\hat{y_i}$. Проводя аналогию с рисунком 4, $\theta$ это $y_i$, а $\hat{\theta}$ это $\hat{y_i}$. Здесь, значение $\hat{y_i}$ будет зависеть от обучающей выборки, а распределение оценки будет показывать, насколько часто эта оценка принимает те или иные значения в зависимости от того, на какой обучающей выборке построена модель.

Возникает два вопроса:

1. Чему в итоге равно истинное значение $y_i$? 
2. Если мы сможем идеально оценить истинные значения $Y$ (т.е. если $y_i = \hat{y_i}$ для всех точек $X$), обнулит ли это ошибку модели?

#### **4.3.1. Истинная зависимость**

Возьмем задачу регрессии. Пусть $X \in \mathbb{R^p}$ и $Y \in \mathbb{R}$. Пусть также между $X$ и $Y$ существует совместное распределение (joint distribution) $Pr(X, Y)$. Между целевой переменной и признаками предположим зависимость вида

$$
Y = f(X) + \epsilon, \qquad \epsilon \sim \mathcal{N}(0, \sigma^2_{\epsilon})
$$

,где $f(X)$ – детерминированная часть (любая функция), а $\epsilon$ – случайная величина (ошибка), распределенная нормально и в среднем равняющаяся нулю. 

Таким образом, $f(X)$ – это функция нашей истинной регрессии. Наша задача – оценить значение этой функции в каждой точке $x_i$.


:::warning
**Обрати внимание**: ввиду присутствия случайной величины $\epsilon$ в выражении, мы никогда не сможем идеально предсказать будущие данные. Другими словами, даже лучшая оценка, равная истинной зависимости $f(X)$, неизбежно будет ошибаться на величину ошибки $\epsilon$. Дальше мы подробнее разберем, как эта неизбежная ошибка влияет на общую ошибку модели.

:::

Технически, при условии квадратичного лосса $L(Y, f(X)) = (Y - f(X))^2$, истинная регрессия минимизирует Expected Prediction Error

$$
EPE(f) = \mathbb{E}(Y - f(X))^2
$$

И тогда в каждой точке истинное значение $y_i$ будет

$$
y_i = f(x_i) = \mathbb{E}(Y|X=x_i)
$$

Это значит, что мы стремимся к тому, чтобы наиболее точно оценить мат. ожидание $\mathbb{E}(Y|X=x_i)$ в каждой точке. Для наглядного представления того, какие точки мы оцениваем, посмотри на рисунок 5, на котором изображен пример с одним категориальным признаком.


 ![](/api/attachments.redirect?id=3901d71c-8fb4-4e0e-a755-4a560596a2bd "aspect=0.6820652173913045")

*Рисунок 5: Истинные значения зависимости* $f(X)$*, которые мы хотим оценить.* *Случайность исходит из величины* $\epsilon$*, распределенной нормально.*


:::info
При условии знания распределений из рисунка 5, мы можем сразу построить идеальную модель, минимизирующую (хотя и не обнуляющую) ошибку. Методы машинного обучения мы используем тогда, когда не знаем о том, как выглядят эти теоретические распределения, и пытаемся оценить их свойства.

:::

#### **4.3.2. Оценка истинной зависимости. Bias-Varince-Noise разложение**

**В итоге, наша цель** – для каждой точки $X=x_i$ подобрать оценку $\hat{f}(x_i)$ истинной регрессии $f(x_i)$ (то есть подобрать оценку мат. ожидания распределения $Y|X=x_i$). Мы также должны помнить о том, что $\hat{f}(x_i)$ – это случайная величина, которая зависит от обучающей выборки, по которой эта оценка рассчитывается. Мы должны подобрать такой $\hat{f}(x_i)$, который бы по всем возможным обучающим выборкам давал бы как можно более точные и близкие к истинному значению $f(x_i)$ оценки. Другими словами, пока что все происходит по аналогии с рисунком 4 из главы 4.2, которую мы разбирали выше.


 ![](/api/attachments.redirect?id=ebecdc27-8ff9-427d-9eb8-75e8b3097362 "aspect=0.5516304347826088")

*Рисунок 6: Разбор условного распределения* $Y|X=A$ *в точке* $X=A$ *из предыдущего рисунка, вместе с распределением оценки* $\hat{E}(Y|X=A)$ *истинного мат. ожидания.*

Для того, чтобы подобрать оптимальную оценку $\hat{f}(x_i)$, нам нужно понимать, из чего состоит эта оценка. Мы возвращаемся к материалу главы 4.2, где ошибка (MSE) оценки состояла из суммы дисперсии оценки и ее квадратичного смещения. Однако в том случае, нашей задачей была оценка фиксированного параметра, и если наша оценка для всех возможных выборок была бы равна этому фиксированному параметру, ошибка (MSE) такой оценки была бы нулевой. Теперь же перед нами стоит задача оценки такого мат. ожидания, которое само по себе генерирует ошибку $\epsilon$. Грубо говоря, даже истинная функция регрессии при предсказании данных выдает определенный (минимальный) уровень ошибки из-за случайной природы самой ошибки $\epsilon$, а потому даже если нам удастся *идеально* оценить истинную регрессию, ошибка такой оценки все равно будет ненулевой. 

Это явление изображено на рисунке 6. Синее распределение – это распределение $Y|X=A$ со своим мат. ожиданием $f(X=A)$, которое мы оцениваем с помощью какой-то оценки $\hat{f}(X=A)$, являющейся случайной величиной и имеющей свое оранжевое распределение. Помни о том, что распределение этой оценки находится с помощью обучения алгоритма на огромном (теоретически бесконечном) количестве разных выборок из совокупности. Мы видим, что оценка смещенная, так как ее мат. ожидание не равно истинному параметру $E(Y|X=A)$. В то же время, разброс оценки, кажется, не такой большой. В любом случае, как мы уже обсуждали, даже если бы эта оценка была детерминированной и всегда была равна $E(Y|X=A)$, мы бы все равно наткнулись на ненулевую ошибку предсказания, так как само по себе синее распределение $Y|X=A$ является случайным и зависит от ошибки $\epsilon$ (вывод из предположения о виде зависимости $Y = f(X) + \epsilon$).


 ![](/api/attachments.redirect?id=80748264-0834-48cd-bf37-4f6d2c674057 "aspect=0.6680272108843532")

*Рисунок *: Возможные случаи сочетания смещения и разброса для разных моделей. Источник:* 

 ![](/api/attachments.redirect?id=c7837817-d3a6-4ccf-9db9-8d79f9c86a61 "aspect=0.9891156462585032")

[https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition](embed:https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://scott.fortmann-roe.com/docs/BiasVariance.html](embed:https://scott.fortmann-roe.com/docs/BiasVariance.html "1")

[https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition](embed:https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition "1")

Давай математически определим, чему же равна ошибка оценки $\hat{f}(x_0)$ на конкретном тестовом значении $X=x_0$, из чего она состоит в задаче машинного обучения и как она отличается от ошибки MSE оценки детерминированного параметра из секции 4.2. Наш выбор – квадратичный функционал ошибки. Мы считаем среднюю тестовую ошибку модели (expected prediction/test error) в точке $x_0$:

$$
\begin{align*}
\mathbb{E}\bigl[(y-\hat{f})^{2}\bigr]
  &=\mathbb{E}\bigl[y^{2}+\hat{f}^{2}-2y\,\hat{f}\bigr] \
  &=\mathbb{E}y^{2}-\bigl(\mathbb{E}y\bigr)^{2}
    +\bigl(\mathbb{E}y\bigr)^{2}
    +\mathbb{E}\hat{f}^{2}-\bigl(\mathbb{E}\hat{f}\bigr)^{2}
    +\bigl(\mathbb{E}\hat{f}\bigr)^{2}
    -2\,\mathbb{E}y\,\mathbb{E}\hat{f} \
  &=\operatorname{Var}y
    +\operatorname{Var}\hat{f}
    +\bigl(\mathbb{E}y\bigr)^{2}
    +\bigl(\mathbb{E}\hat{f}\bigr)^{2}
    -2\,\mathbb{E}y\,\mathbb{E}\hat{f} \
  &=\operatorname{Var}y
    +\operatorname{Var}\hat{f}
    +f^{2}
    +\bigl(\mathbb{E}\hat{f}\bigr)^{2}
    -2\,f\,\mathbb{E}\hat{f} \
  &=\operatorname{Var}y
    +\operatorname{Var}\hat{f}
    +\bigl(\mathbb{E}\hat{f}-f\bigr)^{2} \
  &=\sigma^{2}
    +\operatorname{Var}\hat{f}
    +\operatorname{bias}^{2}!\bigl(f,\hat{f}\bigr),
\end{align*}
$$

,где $f$ – это $f(x_0)$.

Простыми словами – в точке $X=x_0$ ошибка нашей оценки $\hat{f}(x_0)$ равна сумме неизбежной ошибки (неустранимого шума), квадратичного смещения оценки и дисперсии оценки, где смещение оценки измеряет то, насколько оценка отличается от истинного параметра $f(x_0)$ **в среднем по всем обучающим выборкам**, а дисперсия оценки измеряет то, насколько оценка разбросана вокруг своего же мат. ожидания **в среднем по всем обучающим выборкам**. Другими словами, смещенность оценки показывает, насколько хорошо мы настраиваемся на целевую зависимость, в то время как разброс показывает, насколько модель зависит от шума в обучающих выборках. Чем выше зависимость от шума, тем разнообразнее оценки модели в зависимости от тренировочных данных. Интересно, что разброс предсказаний часто напрямую зависит от **сложности модели**: чем гибче наша модель, тем сильнее она подстраивается под шум выборки, и тем соответственно сильнее разброс ее оценок (хотя это и не гарантируется). Об этом подробнее мы поговорим в следующей главе.

На рисунке выше можно увидеть оценки четырех разных моделей, где каждая синяя точка показывает оценку модели на конкретной обучающей выборке. Мы видим, что ошибка модели действительно зависит от смещения и разброса: чем больше оба показателя, тем ниже количество “попаданий” (качество предсказаний).


:::info
По сути, хорошая оценка $\hat{f}(x_0)$ дает значения, в среднем по всем обучающим выборкам близкие к $f(x_0)$.

:::

Неустранимый шум – тот самый шум, который свойственен даже истинной функции регрессии. То есть ошибка истинной функции регрессии равна неустранимому шуму (Irreducible error). Остальная часть ошибки в виде $\text{Bias}^2(\hat{f}(x_0)) + \text{Var}(\hat{f}(x_0))$ является **устранимой** (reducible), то есть это та ошибка, которая напрямую зависит от нашего выбора модели. Таким образом, наша задача – подобрать такую модель, которая будет минимизировать устранимую ошибку, то есть будет выдавать максимально насколько возможно несмещенные и неразбросанные оценки. Об этом поговорим дальше.

Кстати говоря, Expected Prediction Error (Expected Test Error) может усредняться для всех точек $X=x_i$, и таким образом мы можем найти конечную {теоретическую} тестовую ошибку нашей модели на всех возможных точках множества величины $X$:

$$
\text{EPE}(\hat{f}) = \mathbb{E}[Y - \hat{f}(X)]^2
$$

Эта конечная тестовая ошибка состоит из смещений, дисперсий и неустранимых шумов в предсказаниях каждой отдельной тестовой точки $X=x_i$.


 ![](/api/attachments.redirect?id=1356ddbc-328c-4933-b797-8509bec5ecab "aspect=1")


 ![](/api/attachments.redirect?id=9f67bf63-a610-4b62-a892-065df017acbe "aspect=1")

*Рисунок *: Разложение тестовой ошибки на тестовом объекте* $x$ *двух разных моделей. Источник: лекция магистратуры ЦУ*

Разберем, что такое смещение, разброс и естественный шум на конкретном примере и посмотрим на верхний рисунок. На верхних рисунках черным цветом изображены истинные зависимости $Y$ от $X$, а синие функции – это наши оценки этих зависимостей на разных обучающих выборках. В то же время, на нижних рисунках изображены предсказания $\hat{y}$ (синие точки) и истинные возможные значения $y$ (черные точки), где вариативность в предсказаниях вызвана разными обучающими выборками, а вариативность в истинных значениях – зависимостью от случайной ошибки $\epsilon$, предположительно распределенной нормально с мат. ожиданием 0 и стандартным отклонением $\sigma$. Здесь мы также наблюдаем, как итоговая ошибка предсказания на тестовом объекте $x$ зависит от смещения, разброса и естественного шума. Очевидно, что в обоих случаях данные распределены одинаково, а потому черные точки слева и справа совпадают – с неизбежным шумом в данных сделать мы особо ничего не можем. Тем не менее, предсказания (синие точки) сильно отличаются: хотя разброс предсказаний почти одинаков в обеих моделях, смещенность оценки $\hat{y}$ в правой модели значительно ниже, что говорит о том, что правая модель имеет намного лучшую способность настраиваться на целевую зависимость. Очевидно, что итоговая тестовая ошибка на объекте $x$ (да и не только на нем) значительно ниже в правом случае, а значит, правая модель качественнее.

#### **4.3.3. Bias-Variance Tradeoff. Переобучение**

В предыдущей главе мы рассказали о том, что такое смещение и разброс предсказаний, а также разложили тестовую ошибку на три компонента. Теперь же рассмотрим, как выбирать оптимальную модель (а конкретнее, ее сложность), отталкиваясь от того, что мы уже изучили.

Как мы уже выяснили, выбор оптимального алгоритма зависит от его перформанса на тестовых, а не на обучающих данных. Наша цель – подобрать метод, минимизирующий тестовую ошибку. Мы доказали, что эта тестовая ошибка состоит из трех факторов – устранимой ошибки (смещение и дисперсия оценки) и неустранимой ошибки (присущий данным естественный шум). На естественный шум повлиять мы особо не можем, а вот подобрать метод, минимизирующий смещение и дисперсию оценки – как раз наша задача. 

По какому основному критерию различаются разные типы моделей? Мы утверждаем, что этот критерий – это **сложность модели (количество параметров или степеней свободы)**. Регулируя сложность модели, мы можем подобрать оптимальный алгоритм, который минимизирует связку “смещение + разброс”. Мы уже знаем, что разброс оценок сильно зависит от гибкости модели: чем пластичнее модель, тем обычно более разнообразные оценки (в зависимости от тренировочный выборки) она генерирует. В то же время, смещение **тоже** **зависит** от сложности. **__В этом и заключается проблема:__** смещение, в отличии от разброса, **зачастую** **уменьшается** при увеличении количества параметров модели (чем гибче модель, тем в среднем она меньше ошибается), что означает, что **зависимость** смещения от  дисперсии **часто** **обратная**, и чем больше смещение, тем обычно ниже дисперсия, и наоборот. 

 ![](/api/attachments.redirect?id=da2d810d-6a1a-4413-b933-19a1a8a6c689 "aspect=0.578804347826087")

*Рисунок 7: Зависимость (квадратичного) смещения, дисперсии и общей тестовой ошибки от сложности модели. Источник: <https://www.geeksforgeeks.org/ml-bias-variance-trade-off/>*

Неплох для объяснения этого феномена рисунок 7. На горизонтальной оси изображена сложность модели (например, количество параметров или степеней свободы), на вертикальной оси – значения функций. Мы видим, что с увеличением сложности модели, обучающая ошибка уменьшается и в итоге достигает нуля (как, например, в случае с интерполирующей функцией высокой сложности в начале этой главы). Тем не менее, так же видно, что тестовая ошибка (EPE) имеет U-образную форму, и начинает **повышаться** начиная с какого-то значения сложности модели. Почему так происходит? Мы видим, что увеличение сложности модели приводит к уменьшению общей смещенности оценок (действительно, чем модель гибче, тем в среднем ее оценки ближе к истинным параметрам мат. ожидания). В то же время, неустранимая ошибка всегда константна для любой сложности модели, так как этот тип ошибки зависит от изначальных данных, а не от нашей модели. Но также мы видим, что увеличение сложности приводит к увеличению дисперсии оценок – чем модель гибче, тем более разбросанные предсказания она выдает в зависимости от выборки, на которой она обучается. Таким образом, увеличение сложности модели приводит к тому, что вероятностное распределение наших оценок хотя в среднем и приближается к истинным параметрам, но, тем не менее, становится все более разбросанным. При начальном увеличении сложности, уменьшение в квадратичном смещении покрывает увеличение в дисперсии, и общая тестовая ошибка падает. Тем не менее, при дальнейшем увеличении сложности, скорость сокращения квадратичного смещения все уменьшается, а скорость роста дисперсии увеличивается. В какой-то момент, общая тестовая ошибка начинает расти. В машинном обучении это явление называется **__bias-variance tradeoff__**.


 ![](/api/attachments.redirect?id=61e2faae-ddb6-4af1-b8d6-e646ffc8b4f6 "aspect=0.7690217391304349")

*Рисунок 8: Недообучение, оптимальное предсказание и переобучение на выборке. Источник: <https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76>*

Что произойдет, если при построении модели мы пренебрежем анализом оптимальной сложности? Взглянем на рисунок 8. Видно, что в случае, если мы переборщим со сложностью алгоритма, мы наткнемся на **переобучение (overfitting)** – явление, когда модель теряет связь с истинной зависимостью в данных, “ловя шум” обучающей выборки через слишком высокую чувствительность к изменениям в ней. На рисунке 7 этот случай изображен в правой части графика (overfitting zone), на которой видно, что высокая сложность алгоритма порождает настолько высокий разброс предсказаний, что эффект от низкой смещенности нивелируется, а конечная тестовая ошибка достигает высоких значений. Обратная же ситуация, когда мы подбираем слишком ригидный и недостаточно гибкий алгоритм, называется **недообучением (underfitting)** – состоянием, когда модель не может уловить все существующие тенденции в данных (низкий разброс, высокая смещенность – underfitting zone). И пере-, и недообучение приводят к увеличению тестовой ошибки, а потому обоих явлений стоит избегать. Обычно проблема переобучения перед аналитиками стоит острее, так как ее сложнее обнаружить и избежать.

 ![](/api/attachments.redirect?id=c7e7f575-227e-486c-b181-f19fd8acebfb "aspect=1")

 ![](/api/attachments.redirect?id=0010db60-df6c-4a32-abb9-5a0aac23e1e4 "aspect=1")

*Рисунок 9: Выбор оптимальной сложности зависит от распределения данных. Красная кривая – функция тестовой ошибки, серая кривая – функция обучающей ошибки. Три точки разных цветов обозначают три модели разных сложностей. Источник: ISL, Hastie, Tibshirani*

Стоит уточнить, что оптимальная сложность модели – это не какое-то фиксированное значение: оптимальная сложность зависит от самих данных. Взгляни на рисунок 9. Мы видим, что в случае, если сами по себе данные распределены примерно линейно (совместное распределение $f(X,Y)$ примерно линейно), лучшим выбором модели будет линейная или окололинейная модель, а увеличение сложности на таких данных очень быстро приведет к переобучению. Если же данные распределены нелинейно, линейный (или любой ригидный) алгоритм приведет к недообучению, и необходимо будет обучение более комплексной и флексибильной модели. По этой причине, перед проведением ML анализа очень важно смотреть на зависимости и распределения данных в имеющейся выборке (проводить **разведочный анализ данных, или EDA**).

#### **4.3.4. Когда tradeoff не работает**

В предыдущей подглаве мы узнали, как выглядит классический bias-variance tradeoff, который применим не только в теории, но и на практике в большом количестве случаев. Тем не менее, как показывают последние исследования (Belkin et al., 2019), непременное возрастание разброса при убывании смещения **не является абсолютно истинным предположением**.


 ![](/api/attachments.redirect?id=1930f056-5561-43d5-a02a-5a1d96f75e2e "aspect=1")

Рисунок. Источник: Belkin, Hsu et al., 2019.

[https://arxiv.org/pdf/1812.11118](embed:https://arxiv.org/pdf/1812.11118 "1")

[https://arxiv.org/pdf/1812.11118](embed:https://arxiv.org/pdf/1812.11118 "1")

[https://arxiv.org/pdf/1812.11118](embed:https://arxiv.org/pdf/1812.11118 "1")

Изучим рисунок выше. Давай повторим три возможных сценария при обучении модели:

1. Пока модель ригидна (левый край), она не успевает уловить все закономерности данных — это **недообучение** (high bias).
2. Чем больше параметров мы добавляем, тем точнее она подстраивается и тестовая ошибка убывает, достигая **«золотой середины»** (sweet spot).
3. Если идти дальше и раздуть модель слишком сильно, она уже начинает запоминать шум обучающей выборки и теряет обобщающую способность — **переобучение** (high variance); кривая тест-ошибки снова растёт.

Это то, что мы уже изучили в предыдущих главах. 

Теперь возьмём, к примеру, нейросеть и будем наращивать параметры не чуть-чуть, а *очень* *агрессивно*. Классическая U-образная часть остаётся, и в момент, когда модель становится способна идеально «выложить пазл» обучающей выборки (пунктир — **interpolation threshold**), происходит резкий всплеск тест-ошибки. Интуитивно — модель учит всё подряд, включая шум, и на валидации проваливается. Однако:

4. **Парадокс в том**, что если мы **продолжаем** раздувать сеть ещё сильнее, тестовая ошибка снова начинает падать (правый хвост) — иногда даже ниже, чем в классическом «sweet spot».

Интересно, что это применимо не только к нейронным сетям, но и, например, к ансамблевым методам, которые мы будем проходить на следующих неделях. Почему так происходит?

- **Увеличение количества параметров = расширение пространства кандидатов**. Увеличивая параметры, мы расширяем пространство кандидатов и даём алгоритму шанс найти «самую простую» (малонормовую) интерполяцию данных.
- **Пик ошибки — это точка, где модель *только-только* смогла запомнить всё и сделала это самым “напряжённым” способом.** Дальше напряжение спадает: избыточные параметры позволяют распределить подгонку по гладким направлениям без потери точности на обучении.

Так и объясняется парадокс: сверх-параметризованные модели не магически убивают переобучение; они просто дают алгоритму простор выбрать **более гладкие** нулевые-ошибочные решения, которые как раз и снижают тестовую ошибку через **уменьшение дисперсии** (при минимальном смещении).

Таким образом, мы приходим к выводу:

1. Bias-Variance tradeoff хоть и применим к большому количеству случаев, но, тем не менее, не является непреложной истиной, выполняющейся для всех моделей и обучающих данных.
2. Разложение тестового MSE на bias+variance+noise это **не то же самое**, что bias-variance tradeoff. Само по себе разложение остается верным и в тех случаях, когда tradeoff не выполняется.
3. В целом, у компромисса между смещением и дисперсией есть ряд особенностей:
   1. Тестовая ошибка может быть не унимодальной, т.е. минимальная ошибка может достигаться при нескольких уровнях сложности модели;
   2. Смещение и разброс могут быть не строго монотонными;
   3. Как мы уже уточнили, увеличение сложности может приводить к одновременному уменьшению и смещения, и дисперсии. Также возможна обратная ситуация: бывают случаи, когда увеличение количества параметров приводит не только к увеличению дисперсии, но и к росту смещения.

#### **4.3.5. Классический пример**

Давай разберем конкретный жизненный пример, показывающий, как важно правильно подбирать оптимальную сложность модели, которая бы минимизировала тестовую ошибку и, соответственно, обладала бы наибольшей **обобщающей и предсказательной способностью**. В этом примере мы покажем классический bias-variance tradeoff, без “взрывного” роста параметров и каких-то крайних случаев.

 ![](/api/attachments.redirect?id=7070e301-5494-4d2a-96c3-02e7fa30eac1 "aspect=1")

*Рисунок *: Алгоритмы деревьев решений разной сложности (глубины) для трех независимых выборок. Истинная зависимость кубическая.*

Предположим, что истинная зависимость в наших данных принимает кубическую форму:

$$
f(x) = 0.05x^3 - x
$$

Тогда реальные значения будут включать в себя ошибку

$$
y_i = 0.05x_i^3 - x_i + \varepsilon, \qquad \varepsilon \sim \mathcal{N}!\bigl(0,\;2.5^2\bigr)
$$

, где ошибка распределена нормально с нулевым мат.ожиданием и дисперсией, равной 6.25. Мы подобрали такую дисперсию ошибки, чтобы зависимость была неочевидной, но в то же время не слишком размытой.

Сгенерируем три выборки по 40 наблюдений. Эти выборки мы используем в качестве тренировочных для обучения деревьев решений – для каждой выборки, обучим три дерева глубиной 1, 3 и 7 (о подобном ограничении глубины деревьев мы поговорим в главе 5).

Посмотрим на рисунок выше. Мы видим, что для каждой из выборок, увеличение глубины дерева (по сути, увеличение сложности алгоритма) ведет к тому, что модель все дотошнее подстраивается под данные, переобучаясь на шуме в данных и постепенно теряя связь с настоящей зависимостью. В то же время, очевидно, что слишком простые деревья глубиной 1 (“пни”) просто недостаточно гибки для того, чтобы уловить существующую кубическую зависимость. Оптимальной глубиной, дающей хорошую обобщающую способность, кажется значение 3-4. Давай подтвердим эту догадку.

 ![](/api/attachments.redirect?id=c02b0c53-7217-4b14-85cc-5269a6740049 "aspect=1")

*Рисунок. Разложение тестовой MSE и Bias-Variance tradeoff на сгенерированных данных.*

Проведем более тщательный анализ. Сгенерируем 400 обучающих выборок, по 200 наблюдений каждая. Для каждого сета из 400 выборок, обучим деревья решений глубиной от 1 до 15. Получится по 400 деревьев для каждого значения глубины. Для каждого значения глубины, используем 400 обученных деревьев для расчета смещения и дисперсии в 500 тестовых точках, распределенных равномерно на $[-8, 8]$. Далее усредняем показатели по каждой тестовой точке, и получаем финальный показатель смещения и дисперсии для определенной глубины дерева. По всем значениям глубины, проводим такой же анализ. Неустранимым шумом в этом случае будет дисперсия ошибки $6.25$, которая будет одинаковой для всех глубин деревьев (так как ошибка в данных не зависит от алгоритма). Складываем три функции и получаем тестовый MSE на всех значениях глубины дерева.

Мы видим, что минимальный MSE действительно достигается в значениях глубины 3-5. Недостаточная глубина (сложность модели) ведет к недообучению, а избыточная – к переобучению и сильному росту дисперсии. 

Интересно заметить, что при начальном увеличении глубины, дисперсия моделей уменьшается, что как раз говорит о немонотонности дисперсионной функции. Более того, при увеличении глубины деревьев, дисперсия стремится к значению шума, а смещение к нулю: это логично, так как высокая сложность дерева превращает обычную древесную регрессию в интерполирующую функцию, которая в среднем по всем обучающим выборкам почти всегда равна истинной зависимости $f(x)$, в то же время в среднем отклоняющейся от этой зависимости на величину ошибки в наблюдениях.

#### **4.3.6. Методы борьбы с переобучением**

В реальной жизни, чаще всего у нас не будет доступа к большому количеству обучающих выборок, и мы не сможем обучать модели на всех этих выборках и оценить их работу на тестовых данных. Более того, в реальной жизни мы чаще всего даже не будем знать, как выглядит истинная зависимость между переменными (а иначе зачем нам вообще обучать модели), и мы не сможем сравнить эту настоящую связь с обученной на выборках. Именно поэтому были придуманы разные способы по предотвращению переобучения, использующие доступную нам информацию. Каждый из этих эмпирических способов стремится найти тот самый теоретический минимум тестовой ошибки.

Здесь мы перечислим методы, помогающие подобрать оптимальную сложность и избежать переобучения:

- **Выборка специальной структуры.** Иногда можно повлиять на состав данных заранее, чтобы модель не «обманывалась» шумом или особенными примерами. Например, при готовке датасета для классификации можно сознательно включать «трудные» негативные образцы (hard negatives) или обеспечить баланс классов, чтобы алгоритм не затачивался на доминирующий класс. Также применяют принцип Active Learning: итеративно добавляют в обучающий набор те примеры, по которым модель сомневается больше всего.
  Такой подход помогает уменьшить разброс (variance), потому что модель будет видеть более репрезентативные примеры важной «границы» между классами, а не случайный шум. 
- **Увеличение объёма данных.** Чем больше качественных примеров, тем сложнее алгоритму «запомнить» каждый из них. Практика показывает, что при росте объёма выборки обобщающая ошибка стремится к своему априорному минимуму (закон больших чисел). Для табличных данных это может означать сбор дополнительных сессий, экспериментов или исторических записей.
  Главный минус — зачастую сбор новых примеров дорог или невозможен. Но даже пара сотен правильных записей может серьёзно снизить разброс оценок. 
- **Аугментация данных.** Аугментация — это искусственное увеличение объёма выборки через трансформации: в computer vision это повороты, сдвиги, шум; в NLP — замена слов на синонимы, back-translation; в табличных данных — добавление аддитивного шума.
  Формально при каждой эпохе мы генерируем функцию $g$ так, что $x' = g(x), y' = y,$ и обучаем модель на $(x',y')$. Это раздувает пространство наблюдений и помогает снизить variance. 
- **Улучшение качества данных.** Регулярно в датасетах встречаются выбросы, аномалии и дубликаты, которые искривляют границу между классами или вводят артефакты. Очистка данных (outlier removal), коррекция некорректных меток и заполнение пропусков (imputation) существенно уменьшают ложный шум. Хотя это скорее влияет на смещение и общую ошибку, чем на дисперсию, чистые данные позволяют алгоритму точнее «увидеть» реальную зависимость без отвлекающих выбросов. 
- **Использование других данных, задач или готовых моделей.** Transfer learning: дообучение предобученных в глубоких сетях моделей (например, ResNet на ImageNet) на твоей задаче. Многозадачность (multi-task learning) или дообучение на близких по смыслу задачах добавляет полезные индуктивные ограничения. Такой «прицеп» к чужому опыту снижает разброс оценок, особенно когда собственных данных мало. 
- **Сокращение размерности и отбор признаков.** Уменьшаем число входных переменных через PCA, t-SNE, UMAP или методы жадного отбора, в которые, кстати, входит feature importance метод, изученный в прошлой главе по деревьям. В целом, меньше «мертвых» признаков — меньше размер пространства, а значит проще обобщать. Например, в PCA берём первые $k$ компонент так, чтобы захватить 95 % дисперсии, и обучаемся в новом $k$-мерном пространстве. 
- **__Регуляризация__.** Общий термин для алгоритмов, уменьшающих сложность модели. Например, штрафы в функции потерь (проходили несколько недель назад): L2-регуляризация (ridge, weight decay) $\mathcal{L}(w) = \mathcal{L}_{\text{data}}(w) + \lambda \|w\|_2^2$ и L1-регуляризация (lasso) $\mathcal{L}(w) = \mathcal{L}_{\text{data}}(w) + \lambda \|w\|_1$. Это прямо уменьшает capacity модели и снижает дисперсию. 
- **Организация контроля: hold-out, CV и ранняя остановка.** Правильное разбиение данных (train/validation/test) и кросс-валидация позволяют честно оценить, когда модель начинает переобучаться. Early stopping на валидации (например, “если loss не падает 5 эпох подряд — стоп”) прерывает обучение до избыточного подбора под шум. 
- **Выбор модели и архитектуры.** Иногда достаточно перейти с очень гибкой модели (например, глубокого дерева без ограничений) на более «скромную» (ограничение глубины, число слоёв в нейросети). Меньше параметров — ниже дисперсия. 

В четвёртой главе мы глубоко погрузились в проблему обобщающей способности моделей машинного обучения, показав, что истинная цель – минимизировать ошибку на новых, невиданных данных, а не на той же выборке, на которой модель обучалась. Мы рассмотрели модельные предсказания как случайные величины, зависимые от конкретной выборки, и разложили среднеквадратичную ошибку оценки на сумму дисперсии и квадрата смещения, подчеркнув, как именно смещение отражает систематическое отклонение, а дисперсия – чувствительность к шуму выборки. Далее это разложение было расширено до трёх компонент – неустранимого шума, смещения и дисперсии – и наглядно показано, как изменение сложности модели влияет на каждую из них, формируя классическую U-образную форму тестовой ошибки при росте количества параметров. Полученные нами представления о компромиссе между гибкостью и устойчивостью алгоритмов позволили сформулировать принципы выбора оптимальной сложности алгоритмов. В следующей главе мы вернемся к деревьям решений и изучим уже конкретно их методы контроля сложности и предотвращения переобучения.

## **5. Обобщающая способность деревьев решений**

На прошлой лекции мы разобрали, как работает алгоритм деревьев решений и пришли к выводу, что деревья очень легко ловят шум обучающей выборки и в итоге переобучаются. Однако на тот момент мы не знали, как работает переобучение, и уж точно мы не вдавались в суть того, как с этим переобучением бороться. На сегодняшней лекции мы разобрались в теории переобучения и разобрали общие методы, которые помогают с ним справляться. Давай теперь совместим материал двух лекций, и посмотрим, как бороться с переобучением конкретно в “древесных” алгоритмах.

Проблема переобучения в деревьях основывается на том, что если позволить дереву бесконтрольно и неограниченно расти, оно почти всегда вырастет до той степени, когда чуть ли не каждое training наблюдение будет находиться в своем отдельном регионе. Очевидно, это ведет к крайне высокой дисперсии предсказаний, а значит, и к высокой ошибке на тестовых данных.

В целом, эта склонность к переобучению является следствием непараметричности модели, ведь непараметрические модели не “скованы” определенными функциональными требованиями и фиксированным количеством параметром, а потому именно эта непараметричность ведет к высокому риску несдерживаемого роста сложности модели.

Мы знаем, что переобучение само по себе ведет к {иногда сильному} увеличению общей тестовой ошибки. По этой причине, при обучении алгоритмов деревьев решений, просто необходимо применять какие-то “сдерживающие” сложность методы. Эти методы делятся на два класса:

1. **Pre-pruning methods** (сдерживание сложности при обучении).
2. **Post-pruning methods** (стрижка уже обученного дерева).

Разберем в чуть больших деталях оба метода.

### **5.1.  Pre-pruning методы**

Идея этих методов в том, что мы не даём дереву вырасти слишком большим с самого начала, накладывая на обучение определенные ограничения. По сути, эти ограничения являются гиперпараметрами, которые нужно регулировать до начала обучения модели. Правильный подбор таких гиперпараметров может помочь избежать (или смягчить) переобучение. 

Таким образом, эти ограничения могут быть (в скобках указаны гиперпараметры Python библиотеки `sklearn.tree.DecisionTree*`):

- Глубина дерева (`max_depth`). При попадании в какой-то узел, мы проверяем условие “глубина дерева на этом узле > k”, и если условие соблюдается, мы объявляем вершину терминальной (листом) и переходим на проверку соблюдения условия на других узлах. Если глубина дерева во всех узлах-претендентах превысила 10, мы останавливаем обучение дерева и объявляем алгоритм обученным. По той же логике мы проверяем соблюдение следующих ограничений.
- Минимальное число объектов в узле (`min_samples_split`, `min_samples_leaf`).
- Минимальное уменьшение ошибки при делении (`min_impurity_decrease`). Если следующее лучшее деление узла приводит к уменьшению ошибки (общей неопределенности) меньшему, чем заданный порог, вершина объявляется листом.
- Максимальное количество листьев (`max_leaf_nodes`). Считает общее количество листьев в дереве и при превышении завершает обучении. При применении этого ограничения, как раз и будет иметь значение то, в каком порядке мы обучаем дерево (level-wise/leaf-wise tree growth). Мы проходили это в главе 2.2.1.
- Максимальное количество признаков при поиске лучшего разбиения (`max_features`). Особенно полезно будет в дальнейшем при обучении ансамбля случайных лесов.

Методы раннего сдерживания переобучения хороши своими свойствами простоты применения и низкой вычислительной стоимости. Тем не менее, подобные ограничения роста дерева могут привести к тому, что сплит дерева, следующий после окончательного сплита, приводит к сильному улучшению качества модели (ситуация, когда после незначительного сплита следует очень значительный). Это приводит к значительно меньшей гибкости и серьезному риску **недообучения** дерева.

### **5.2.  Post-pruning методы**

Этот класс методов по сдерживанию переобучения предполагает изначальное построение полноценного неограниченного дерева, которое впоследствии “стригут” до состояния оптимального поддерева, что, конечно, немного увеличивает смещение оценок, но в то же время приводит к значительному уменьшению дисперсии предсказаний, таким образом понижая общую тестовую ошибку.

Эти методы стрижки дают гораздо бОльшую гибкость в выборе оптимального решения, и ведут к гораздо меньшему риску недообучения в сравнении с pre-pruning методами. Тем не менее, сложность реализации и вычислительная стоимость “стрижки” выше, и перед применением постпрунинга нужно оценить, насколько наши вычислительные ресурсы позволяют проведение такого анализа. В некоторых случаях будет лучше применить более простой pre-pruning.

В теории, чтобы добиться наилучшей стрижки обученного дерева, нужно проверить **все** возможные поддеревья этого дерева и выбрать то поддерево, которое будет выдавать наименьшую валидационную ошибку. Оценка валидационной ошибки может проводиться с помощью кросс-валидации. После этого, можно измерить окончательную тестовую ошибку этого поддерева как показатель качества решения. Однако этот метод крайне затратен, так как проведение кросс-валидации для каждого поддерева становится технически невыполнимым для дерева с большим количеством листьев.

По этой причине, как при самом обучении дерева, так и при стрижке мы используем **жадные** алгоритмы. Приведем пример такого алгоритма стрижки дерева, часто использующегося в рамках CART. Этот алгоритм называется **cost-complexity pruning (или weakest link pruning).** Этот метод позволяет определить последовательность из конкретных поддеревьев, и сравнить их валидационные ошибки. Это дает нам возможность избежать оценивания ошибки всех поддеревьев.

Разберем дерево регрессии при квадратичном лоссе. Вспомним **меру неопределенности**:

$$
H(R) = \frac{1}{|R|} \sum_{(x_i, y_i) \in R} (y_i - \bar{y})^2
$$

А теперь переформулируем ее в вид

$$
H_m(T) = \frac{1}{|R_m|} \sum_{(x_i, y_i) \in R_m} (y_i - \bar{y})^2,
$$

где m – регион (лист дерева), а T обозначает дерево на конкретном шаге (в начале $T=T_0$, где $T_0$ это полностью обученное дерево). В целом, мы определяем поддерево $T \subset T_0$ как любое дерево, которое может быть получено путём **обрезки** дерева $T_0$, то есть схлопывания любого количества его внутренних (не терминальных) узлов.

Определим критерий cost complexity (функцию стоимости):

$$
C_{\alpha}(T) = \sum_{m=1}^{|T|} |R_m| H_m(T) + \alpha |T|,
$$

контролируемый гиперпараметром $\alpha$. Идея заключается в том, чтобы для каждого значения $\alpha$ найти поддерево $T_\alpha \subseteq T_0$, минимизирующее функцию стоимости $C_\alpha(T)$. Гиперпараметр $\alpha \geq 0$ задает компромисс между **размером дерева** и **качеством его подгонки к данным**. Большие значения $\alpha$ приводят к меньшим деревьям $T_\alpha$​, и наоборот — при меньших значениях $\alpha$ дерево получается размером больше. При $\alpha = 0$ решением является полное дерево $T_0$​. Для каждого значения $\alpha$ можно показать, что существует **единственное** наименьшее поддерево $T_\alpha$, минимизирующее функцию $C_\alpha(T)$. 

Для нахождения интересующей нас последовательности поддеревьев, среди которых мы будем выбирать оптимальное, используется **cost complexity pruning**: при постепенном увеличении $\alpha$ начиная с нуля, мы последовательно один за другим **схлопываем тот внутренний узел**, при удалении которого наблюдается **наименьшее увеличение суммы** $\sum_m |R_m| H_m(T)$, и продолжаем процесс (увеличиваем $\alpha$)  до тех пор, пока не получим дерево из одной вершины (корня). Это порождает конечную последовательность поддеревьев, и у каждого поддерева есть свой $\alpha$. Подбор оптимального гиперпараметра $\hat{\alpha}$ (генерирующего поддерево с наименьшей валидационной ошибкой) может осуществляться с помощью **пятикратной или десятикратной кросс-валидации**. Итоговое постриженное дерево — это $T_{\hat{\alpha}}$, и его мы объявляем окончательным результатом обучения.


**Резюмируем алгоритм деревьев решений, который мы прошли на этой неделе.** 

Невысокая точность предсказаний и сильная склонность к переобучению, зачастую, перекрывают такие положительные стороны деревьев, как интерпретируемость и гибкость. Тем не менее, дерево решений – один из классических и фундаментальных алгоритмов машинного обучения. Само по себе дерево не всегда является лучшим выбором для дата сайентиста при анализе зависимостей каких-то явлений, особенно, когда целью является получение более точных, а не интерпретируемых результатов. Тем не менее, дерево решений может выступать в роли крепкого строительного блока для гораздо более мощных – **ансамблевых** – методов, о которых мы поговорим на следующих неделях.

---

## Итоги

По итогам этой недели ты узнал о нескольких **фундаментальных** явлениях в машинном обучении:

- Что такое дерево решений и как оно работает;
- Как обучать деревья решений: функционал качества, мера неопределенности, разные функции потерь в задачах регрессии и классификации;
- Сильные и слабые стороны деревьев. Когда лучше использовать древесный алгоритм, а когда – линейную модель;
- Статистическая оценка параметров и распределения оценок;
- Параметры в машинном обучении. Как истинная функция регрессии связана с условными мат. ожиданиями.
- Как оценивать параметры в МО: разложение функции ошибки на три компоненты. Bias-variance tradeoff, или “почему самая сложная модель – не самая качественная?”;
- Проблемы переобучения и недообучения, методы борьбы с переобучением в МО;
- Методы борьбы с переобучением в деревьях решений.


